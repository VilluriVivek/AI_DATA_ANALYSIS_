{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "\n",
      "--- Question 5: Label Encoding vs One-Hot Encoding ---\n",
      "Label Encoded 'Sex':\n",
      "   Sex_LabelEncoded\n",
      "0                 1\n",
      "1                 0\n",
      "2                 0\n",
      "3                 0\n",
      "4                 1\n",
      "\n",
      "One-Hot Encoded 'Sex':\n",
      "   Sex_male\n",
      "0      True\n",
      "1     False\n",
      "2     False\n",
      "3     False\n",
      "4      True\n",
      "\n",
      "--- Question 6: Combining Min-Max Scaling and Standardization ---\n",
      "Scaled Data with Min-Max and Standardization\n",
      "Min-Max Scaled Data (First 5 rows): [[0.27117366 0.01415106]\n",
      " [0.4722292  0.13913574]\n",
      " [0.32143755 0.01546857]\n",
      " [0.43453129 0.1036443 ]\n",
      " [0.43453129 0.01571255]]\n",
      "Standardized Data (First 5 rows): [[-0.5924806  -0.50244517]\n",
      " [ 0.63878901  0.78684529]\n",
      " [-0.2846632  -0.48885426]\n",
      " [ 0.40792596  0.42073024]\n",
      " [ 0.40792596 -0.48633742]]\n",
      "\n",
      "--- Question 7: Handling Multiple Categorical Features ---\n",
      "   Embarked_Q  Embarked_S\n",
      "0       False        True\n",
      "1       False       False\n",
      "2       False        True\n",
      "3       False        True\n",
      "4       False        True\n",
      "\n",
      "--- Question 8: Ordinal Encoding for 'Pclass' ---\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unsorted categories are not supported for numerical categories",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 59\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Question 8: Ordinal Encoding for \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPclass\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     58\u001b[0m ordinal_encoder \u001b[38;5;241m=\u001b[39m OrdinalEncoder(categories\u001b[38;5;241m=\u001b[39m[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[0;32m---> 59\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPclass_OrdinalEncoded\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mordinal_encoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPclass\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPclass\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPclass_OrdinalEncoded\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mhead())\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# Question 9: Impact of Scaling on Decision Tree and SVM\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_set_output.py:319\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 319\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    322\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    323\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    324\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    325\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:918\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    903\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    904\u001b[0m             (\n\u001b[1;32m    905\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) has a `transform`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    913\u001b[0m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m    914\u001b[0m         )\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    917\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m--> 918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m    919\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    920\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:1515\u001b[0m, in \u001b[0;36mOrdinalEncoder.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1508\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   1509\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown_value should only be set when \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1510\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhandle_unknown is \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_encoded_value\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1511\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munknown_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1512\u001b[0m     )\n\u001b[1;32m   1514\u001b[0m \u001b[38;5;66;03m# `_fit` will only raise an error when `self.handle_unknown=\"error\"`\u001b[39;00m\n\u001b[0;32m-> 1515\u001b[0m fit_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhandle_unknown\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_unknown\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_and_ignore_missing_for_infrequent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1520\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1521\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_missing_indices \u001b[38;5;241m=\u001b[39m fit_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmissing_indices\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1523\u001b[0m cardinalities \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mlen\u001b[39m(categories) \u001b[38;5;28;01mfor\u001b[39;00m categories \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategories_]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:155\u001b[0m, in \u001b[0;36m_BaseEncoder._fit\u001b[0;34m(self, X, handle_unknown, ensure_all_finite, return_counts, return_and_ignore_missing_for_infrequent)\u001b[0m\n\u001b[1;32m    153\u001b[0m     stop_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39misnan(sorted_cats[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(sorted_cats[:stop_idx] \u001b[38;5;241m!=\u001b[39m cats[:stop_idx]):\n\u001b[0;32m--> 155\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(error_msg)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle_unknown \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    158\u001b[0m     diff \u001b[38;5;241m=\u001b[39m _check_unknown(Xi, cats)\n",
      "\u001b[0;31mValueError\u001b[0m: Unsorted categories are not supported for numerical categories"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, MinMaxScaler, StandardScaler, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Load Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Display first few rows\n",
    "print(df.head())\n",
    "\n",
    "# Question 5: Label Encoding vs One-Hot Encoding for 'Sex' feature\n",
    "print(\"\\n--- Question 5: Label Encoding vs One-Hot Encoding ---\")\n",
    "# Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "df['Sex_LabelEncoded'] = label_encoder.fit_transform(df['Sex'])\n",
    "\n",
    "# One-Hot Encoding\n",
    "df = pd.get_dummies(df, columns=['Sex'], drop_first=True)\n",
    "\n",
    "print(\"Label Encoded 'Sex':\")\n",
    "print(df[['Sex_LabelEncoded']].head())\n",
    "print(\"\\nOne-Hot Encoded 'Sex':\")\n",
    "print(df[['Sex_male']].head())\n",
    "\n",
    "# Question 6: Combining Feature Scaling Techniques\n",
    "print(\"\\n--- Question 6: Combining Min-Max Scaling and Standardization ---\")\n",
    "X = df[['Age', 'Fare']].fillna(df[['Age', 'Fare']].mean())  # Handle missing values\n",
    "y = df['Survived']\n",
    "\n",
    "# Min-Max Scaling\n",
    "scaler_minmax = MinMaxScaler()\n",
    "X_minmax = scaler_minmax.fit_transform(X)\n",
    "\n",
    "# Standardization\n",
    "scaler_std = StandardScaler()\n",
    "X_std = scaler_std.fit_transform(X)\n",
    "\n",
    "# Split and demonstrate\n",
    "X_train_minmax, X_test_minmax, y_train, y_test = train_test_split(X_minmax, y, test_size=0.3, random_state=42)\n",
    "X_train_std, X_test_std = train_test_split(X_std, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Scaled Data with Min-Max and Standardization\")\n",
    "print(\"Min-Max Scaled Data (First 5 rows):\", X_minmax[:5])\n",
    "print(\"Standardized Data (First 5 rows):\", X_std[:5])\n",
    "\n",
    "# Question 7: Handling Multiple Categorical Features using One-Hot Encoding\n",
    "print(\"\\n--- Question 7: Handling Multiple Categorical Features ---\")\n",
    "df = pd.get_dummies(df, columns=['Embarked'], drop_first=True)\n",
    "print(df[['Embarked_Q', 'Embarked_S']].head())  # 'Embarked_Q' and 'Embarked_S' are the encoded columns\n",
    "\n",
    "# Question 8: Ordinal Encoding for 'Pclass'\n",
    "print(\"\\n--- Question 8: Ordinal Encoding for 'Pclass' ---\")\n",
    "ordinal_encoder = OrdinalEncoder(categories=[['3', '2', '1']])\n",
    "df['Pclass_OrdinalEncoded'] = ordinal_encoder.fit_transform(df[['Pclass']])\n",
    "print(df[['Pclass', 'Pclass_OrdinalEncoded']].head())\n",
    "\n",
    "# Question 9: Impact of Scaling on Decision Tree and SVM\n",
    "print(\"\\n--- Question 9: Impact of Scaling on Decision Tree and SVM ---\")\n",
    "# Decision Tree Model\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train_minmax, y_train)\n",
    "dt_pred = dt_model.predict(X_test_minmax)\n",
    "dt_accuracy = accuracy_score(y_test, dt_pred)\n",
    "\n",
    "# SVM Model\n",
    "svm_model = SVC(random_state=42)\n",
    "svm_model.fit(X_train_std, y_train)\n",
    "svm_pred = svm_model.predict(X_test_std)\n",
    "svm_accuracy = accuracy_score(y_test, svm_pred)\n",
    "\n",
    "print(f\"Decision Tree accuracy with Min-Max Scaling: {dt_accuracy:.4f}\")\n",
    "print(f\"SVM accuracy with Standardization: {svm_accuracy:.4f}\")\n",
    "\n",
    "# Question 10: Custom Transformation for High Cardinality Categorical Features\n",
    "print(\"\\n--- Question 10: Custom Transformation for High Cardinality Categorical Features ---\")\n",
    "def custom_high_cardinality_encoding(df, column_name):\n",
    "    \"\"\"\n",
    "    Custom transformation function for encoding high cardinality categorical features\n",
    "    \"\"\"\n",
    "    freq = df[column_name].value_counts()\n",
    "    rare_categories = freq[freq < 10].index  # Treat categories with frequency < 10 as 'Other'\n",
    "    df[column_name] = df[column_name].apply(lambda x: x if x not in rare_categories else 'Other')\n",
    "    return df\n",
    "\n",
    "# Apply to 'Ticket' column (which has many unique values)\n",
    "df = custom_high_cardinality_encoding(df, 'Ticket')\n",
    "print(df[['Ticket']].head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
