{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1**: Checking Null Values for Completeness\n",
    "\n",
    "**Description**: Verify if there are any null values in a dataset, which indicate incomplete data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null Value Counts:\n",
      "Column Name  Null Count\n",
      "       col1           1\n",
      "       col2           1\n",
      "       col3           1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def check_null_values(csv_file):\n",
    "    \"\"\"\n",
    "    Checks for null values in a dataset and prints the count of null values for each column.\n",
    "\n",
    "    Args:\n",
    "        csv_file (str): Path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame containing the count of null values for each column,\n",
    "                          or None if an error occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the CSV file into a Pandas DataFrame\n",
    "        df = pd.read_csv(csv_file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {csv_file}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading CSV file: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Get the count of null values for each column\n",
    "    null_value_counts = df.isnull().sum()\n",
    "\n",
    "    # If there are no null values, return a message\n",
    "    if null_value_counts.sum() == 0:\n",
    "        print(\"No null values found in the dataset.\")\n",
    "        return None\n",
    "\n",
    "    # Create a DataFrame to display the null value counts\n",
    "    null_value_df = pd.DataFrame({\n",
    "        'Column Name': null_value_counts.index,\n",
    "        'Null Count': null_value_counts.values\n",
    "    })\n",
    "\n",
    "    return null_value_df\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the null value check and print the results.\n",
    "    \"\"\"\n",
    "    # Provide the path to your CSV file\n",
    "    csv_file = 'data_with_nulls.csv'  # Replace with your actual file path\n",
    "\n",
    "    # Create a dummy CSV file with null values for demonstration\n",
    "    try:\n",
    "        with open(csv_file, 'w') as f:\n",
    "            f.write(\"col1,col2,col3\\n1,4,7\\n2,,8\\n3,5,\\n,6,9\")\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "\n",
    "\n",
    "    # Check for null values\n",
    "    null_value_df = check_null_values(csv_file)\n",
    "\n",
    "    # Print the results\n",
    "    if null_value_df is not None:\n",
    "        print(\"Null Value Counts:\")\n",
    "        print(null_value_df.to_string(index=False))\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2**: Checking Data Type Validity\n",
    "\n",
    "**Description**: Ensure that columns contain data of expected types, e.g., ages are integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Type Check Results:\n",
      "name: Invalid\n",
      "age: Valid\n",
      "salary: Valid\n",
      "city: Invalid\n",
      "is_active: Valid\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def check_data_types(csv_file, expected_types):\n",
    "    \"\"\"\n",
    "    Checks if columns in a dataset contain data of the expected types.\n",
    "\n",
    "    Args:\n",
    "        csv_file (str): Path to the CSV file.\n",
    "        expected_types (dict): A dictionary where keys are column names and values are\n",
    "            the expected data types (e.g., {'age': int, 'name': str, 'salary': float}).\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are column names, and values are either:\n",
    "            - True: if all values in the column match the expected data type,\n",
    "            - False: if any value in the column does not match the expected data type,\n",
    "            - A string error message: If a column is not found.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the CSV file into a Pandas DataFrame\n",
    "        df = pd.read_csv(csv_file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {csv_file}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading CSV file: {e}\")\n",
    "        return None\n",
    "\n",
    "    results = {}\n",
    "    for column, expected_type in expected_types.items():\n",
    "        if column not in df.columns:\n",
    "            results[column] = f\"Column '{column}' not found.\"\n",
    "            continue  # Move to the next column\n",
    "\n",
    "        # Get the actual data type of the column\n",
    "        actual_type = df[column].dtype\n",
    "\n",
    "        # Check for type match.  For numeric, allow both int and float\n",
    "        if expected_type in (int, float) and pd.api.types.is_numeric_dtype(actual_type):\n",
    "            results[column] = True\n",
    "        elif actual_type == expected_type:\n",
    "            results[column] = True\n",
    "        else:\n",
    "            results[column] = False\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the data type check and print the results.\n",
    "    \"\"\"\n",
    "    # Provide the path to your CSV file\n",
    "    csv_file = 'data_types.csv'  # Replace with your actual file path\n",
    "\n",
    "    # Define the expected data types for the columns\n",
    "    expected_types = {\n",
    "        'name': str,\n",
    "        'age': int,\n",
    "        'salary': float,\n",
    "        'city': str,\n",
    "        'is_active': bool\n",
    "    }\n",
    "\n",
    "    # Create a dummy CSV file for demonstration\n",
    "    try:\n",
    "        with open(csv_file, 'w') as f:\n",
    "            f.write(\"name,age,salary,city,is_active\\nAlice,30,50000.00,New York,True\\nBob,25,60000.50,Los Angeles,False\\nCharlie,35,75000,Chicago,True\\nDavid,40,100000,Houston,False\\nEve,22,45000,Miami,True\\nFrank,28,55000,Dallas,True\\n\")\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "\n",
    "    # Check data types\n",
    "    results = check_data_types(csv_file, expected_types)\n",
    "\n",
    "    # Print the results\n",
    "    if results is not None:\n",
    "        print(\"Data Type Check Results:\")\n",
    "        for column, result in results.items():\n",
    "            if isinstance(result, str):\n",
    "                print(f\"{column}: {result}\")  # Print the error message\n",
    "            else:\n",
    "                print(f\"{column}: {'Valid' if result else 'Invalid'}\")\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3**: Verify Uniqueness of Identifiers\n",
    "\n",
    "**Description**: Check if a dataset has unique identifiers (e.g., emails)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'email' contains duplicate values.\n",
      "Duplicate values:\n",
      "alice@example.com\n",
      "  bob@example.com\n",
      "alice@example.com\n",
      "  bob@example.com\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def check_unique_identifiers(csv_file, id_column):\n",
    "    \"\"\"\n",
    "    Checks if a specified column in a dataset has unique identifiers.\n",
    "\n",
    "    Args:\n",
    "        csv_file (str): Path to the CSV file.\n",
    "        id_column (str): Name of the column to check for uniqueness (e.g., 'email', 'customer_id').\n",
    "\n",
    "    Returns:\n",
    "        bool: True if all values in the specified column are unique, False otherwise.\n",
    "        pandas.Series: A Series containing the duplicate values, if any.  Returns an empty Series if no duplicates.\n",
    "                        Returns None if there are errors\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the CSV file into a Pandas DataFrame\n",
    "        df = pd.read_csv(csv_file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {csv_file}\")\n",
    "        return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading CSV file: {e}\")\n",
    "        return None, None\n",
    "\n",
    "    # Check if the specified column exists\n",
    "    if id_column not in df.columns:\n",
    "        print(f\"Error: Column '{id_column}' not found in the file.\")\n",
    "        return None, None\n",
    "\n",
    "    # Check for duplicates\n",
    "    duplicates = df[id_column].duplicated(keep=False) #keep=False marks all duplicates as True\n",
    "    has_duplicates = duplicates.any()\n",
    "    duplicate_values = df[id_column][duplicates] # Extract the duplicate values\n",
    "\n",
    "    return not has_duplicates, duplicate_values\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the unique identifier check and print the results.\n",
    "    \"\"\"\n",
    "    # Provide the path to your CSV file\n",
    "    csv_file = 'customer_data.csv'  # Replace with your actual file path\n",
    "\n",
    "    # Specify the column to check for uniqueness\n",
    "    id_column = 'email'  # You can change this to 'customer_id' or any other identifier column\n",
    "\n",
    "    # Create a dummy CSV file for demonstration\n",
    "    try:\n",
    "        with open(csv_file, 'w') as f:\n",
    "            f.write(\"customer_id,name,email\\n1,Alice,alice@example.com\\n2,Bob,bob@example.com\\n3,Charlie,charlie@example.com\\n4,David,david@example.com\\n5,Eve,alice@example.com\\n6,Frank,bob@example.com\") #Alice and Bob's email are duplicated\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "\n",
    "    # Check for unique identifiers\n",
    "    is_unique, duplicate_values = check_unique_identifiers(csv_file, id_column)\n",
    "\n",
    "    # Print the results\n",
    "    if is_unique is not None:\n",
    "        if is_unique:\n",
    "            print(f\"All values in column '{id_column}' are unique.\")\n",
    "        else:\n",
    "            print(f\"Column '{id_column}' contains duplicate values.\")\n",
    "            print(\"Duplicate values:\")\n",
    "            print(duplicate_values.to_string(index=False))\n",
    "    else:\n",
    "        print(\"An error occurred while checking for unique identifiers.\")\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 4: Validate Email Format Using Regex\n",
    "\n",
    "Description: Validate if email addresses in a dataset have the correct format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email Format Validation Results:\n",
      "                  email  is_valid\n",
      "      alice@example.com      True\n",
      "          invalid-email     False\n",
      "       charlie@test.org      True\n",
      "         missing@dotcom     False\n",
      "     eve@sub.domain.com      True\n",
      "frank.last@domain.co.in      True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def validate_email_format(csv_file, email_column):\n",
    "    \"\"\"\n",
    "    Validates email addresses in a dataset using a regular expression pattern.\n",
    "\n",
    "    Args:\n",
    "        csv_file (str): Path to the CSV file.\n",
    "        email_column (str): Name of the column containing email addresses.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame with the original email addresses and a boolean 'is_valid' column,\n",
    "                          indicating whether each email is valid (True) or invalid (False).\n",
    "                          Returns None if there are errors.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the CSV file into a Pandas DataFrame\n",
    "        df = pd.read_csv(csv_file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {csv_file}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading CSV file: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Check if the email column exists\n",
    "    if email_column not in df.columns:\n",
    "        print(f\"Error: Email column '{email_column}' not found in the file.\")\n",
    "        return None\n",
    "\n",
    "    # Basic regex pattern for email validation.\n",
    "    # It checks for:\n",
    "    # - One or more characters (excluding spaces and @) before the @ symbol\n",
    "    # - An @ symbol\n",
    "    # - One or more characters (excluding spaces) after the @ symbol\n",
    "    # - A dot (.)\n",
    "    # - Two or more characters (excluding spaces) after the dot\n",
    "    email_pattern = r\"^[^\\s@]+@[^\\s@]+\\.[^\\s@]{2,}$\"\n",
    "\n",
    "    # Apply the regex pattern to validate email addresses\n",
    "    is_valid = df[email_column].str.match(email_pattern)\n",
    "\n",
    "    # Create a new DataFrame with the original emails and the validation results\n",
    "    results_df = pd.DataFrame({\n",
    "        email_column: df[email_column],\n",
    "        'is_valid': is_valid\n",
    "    })\n",
    "\n",
    "    return results_df\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the email format validation and print the results.\n",
    "    \"\"\"\n",
    "    # Provide the path to your CSV file\n",
    "    csv_file = 'customer_emails.csv'  # Replace with your actual file path\n",
    "\n",
    "    # Specify the column containing email addresses\n",
    "    email_column = 'email'\n",
    "\n",
    "    # Create a dummy CSV file for demonstration\n",
    "    try:\n",
    "        with open(csv_file, 'w') as f:\n",
    "            f.write(\"customer_id,name,email\\n1,Alice,alice@example.com\\n2,Bob,invalid-email\\n3,Charlie,charlie@test.org\\n4,David,missing@dotcom\\n5,Eve,eve@sub.domain.com\\n6,Frank,frank.last@domain.co.in\\n\")\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "\n",
    "    # Validate email formats\n",
    "    results_df = validate_email_format(csv_file, email_column)\n",
    "\n",
    "    # Print the results\n",
    "    if results_df is not None:\n",
    "        print(\"Email Format Validation Results:\")\n",
    "        print(results_df.to_string(index=False))\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 5: Check for Logical Age Validity\n",
    "\n",
    "Description: Ensure ages are within a reasonable human range (e.g., 0-120)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age Validation Results:\n",
      " age  is_valid\n",
      "  30      True\n",
      " 150     False\n",
      "  25      True\n",
      "  -5     False\n",
      "  80      True\n",
      "  60      True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def validate_age_range(csv_file, age_column, min_age=0, max_age=120):\n",
    "    \"\"\"\n",
    "    Checks if ages in a dataset are within a specified range.\n",
    "\n",
    "    Args:\n",
    "        csv_file (str): Path to the CSV file.\n",
    "        age_column (str): Name of the column containing ages.\n",
    "        min_age (int, optional): The minimum valid age (inclusive). Defaults to 0.\n",
    "        max_age (int, optional): The maximum valid age (inclusive). Defaults to 120.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame with the original ages and a boolean 'is_valid' column,\n",
    "                          indicating whether each age is within the valid range (True) or not (False).\n",
    "                          Returns None if there are errors.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the CSV file into a Pandas DataFrame\n",
    "        df = pd.read_csv(csv_file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {csv_file}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading CSV file: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Check if the age column exists\n",
    "    if age_column not in df.columns:\n",
    "        print(f\"Error: Age column '{age_column}' not found in the file.\")\n",
    "        return None\n",
    "\n",
    "    # Validate ages against the specified range\n",
    "    is_valid = (df[age_column] >= min_age) & (df[age_column] <= max_age)\n",
    "\n",
    "    # Create a new DataFrame with the original ages and the validation results\n",
    "    results_df = pd.DataFrame({\n",
    "        age_column: df[age_column],\n",
    "        'is_valid': is_valid\n",
    "    })\n",
    "\n",
    "    return results_df\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the age validity check and print the results.\n",
    "    \"\"\"\n",
    "    # Provide the path to your CSV file\n",
    "    csv_file = 'customer_ages.csv'  # Replace with your actual file path\n",
    "\n",
    "    # Specify the column containing ages\n",
    "    age_column = 'age'\n",
    "\n",
    "    # Define the valid age range\n",
    "    min_age = 0\n",
    "    max_age = 120\n",
    "\n",
    "    # Create a dummy CSV file for demonstration\n",
    "    try:\n",
    "        with open(csv_file, 'w') as f:\n",
    "            f.write(\"customer_id,name,age\\n1,Alice,30\\n2,Bob,150\\n3,Charlie,25\\n4,David,-5\\n5,Eve,80\\n6,Frank,60\\n\")\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "\n",
    "    # Validate ages\n",
    "    results_df = validate_age_range(csv_file, age_column, min_age, max_age)\n",
    "\n",
    "    # Print the results\n",
    "    if results_df is not None:\n",
    "        print(\"Age Validation Results:\")\n",
    "        print(results_df.to_string(index=False))\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 6: Identify and Handle Missing Data\n",
    "\n",
    "Description: Identify missing values in a dataset and impute them using a simple strategy (e.g., mean)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame with Imputed Values (Mean Imputation for col1, col2, col3):\n",
      "   col1  col2  col3 col4\n",
      "0  1.00   4.0   7.0    a\n",
      "1  2.00   5.0   8.0    b\n",
      "2  3.00   5.0   8.5    c\n",
      "3  2.75   6.0   9.0    d\n",
      "4  5.00   5.0  10.0    e\n",
      "\n",
      "DataFrame with Imputed Values (Median Imputation for col3):\n",
      "   col1  col2  col3 col4\n",
      "0   1.0   4.0   7.0    a\n",
      "1   2.0   NaN   8.0    b\n",
      "2   3.0   5.0   8.5    c\n",
      "3   NaN   6.0   9.0    d\n",
      "4   5.0   NaN  10.0    e\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "handle_missing_data() got an unexpected keyword argument 'constant_value'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 100\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[38;5;28mprint\u001b[39m(imputed_df)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 100\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 92\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28mprint\u001b[39m(imputed_df)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# Impute missing values of col1 and col2 using a constant value\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m imputed_df \u001b[38;5;241m=\u001b[39m \u001b[43mhandle_missing_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconstant\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns_to_impute\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcol1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcol2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstant_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m imputed_df \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mDataFrame with Imputed Values (Constant Imputation (0) for col1 and col2):\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: handle_missing_data() got an unexpected keyword argument 'constant_value'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def handle_missing_data(csv_file, strategy='mean', columns_to_impute=None):\n",
    "    \"\"\"\n",
    "    Identifies missing values in a dataset and imputes them using a specified strategy.\n",
    "\n",
    "    Args:\n",
    "        csv_file (str): Path to the CSV file.\n",
    "        strategy (str, optional): The imputation strategy.  Valid values are 'mean', 'median', or 'constant'.\n",
    "            Defaults to 'mean'.\n",
    "        columns_to_impute (list, optional): A list of column names to impute. If None, impute all numeric columns.\n",
    "        constant_value (int or float, optional): The constant value to use for imputation with strategy='constant'.\n",
    "            Required if strategy='constant'.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A new DataFrame with missing values imputed, or None if an error occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the CSV file into a Pandas DataFrame\n",
    "        df = pd.read_csv(csv_file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {csv_file}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading CSV file: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Handle the case where columns_to_impute is None\n",
    "    if columns_to_impute is None:\n",
    "        # Impute only numeric columns\n",
    "        numeric_df = df.select_dtypes(include=np.number)\n",
    "        columns_to_impute = numeric_df.columns.tolist()\n",
    "\n",
    "    # Check if the strategy is valid\n",
    "    if strategy not in ['mean', 'median', 'constant']:\n",
    "        print(f\"Error: Invalid imputation strategy '{strategy}'.  Must be 'mean', 'median', or 'constant'.\")\n",
    "        return None\n",
    "\n",
    "    # Check if columns_to_impute are in the DataFrame\n",
    "    for col in columns_to_impute:\n",
    "        if col not in df.columns:\n",
    "            print(f\"Error: Column '{col}' not found in the file.\")\n",
    "            return None\n",
    "\n",
    "    # Impute the missing values\n",
    "    df_imputed = df.copy()  # Create a copy to avoid modifying the original DataFrame\n",
    "    for col in columns_to_impute:\n",
    "        if strategy == 'mean':\n",
    "            df_imputed[col] = df_imputed[col].fillna(df_imputed[col].mean())\n",
    "        elif strategy == 'median':\n",
    "            df_imputed[col] = df_imputed[col].fillna(df_imputed[col].median())\n",
    "        elif strategy == 'constant':\n",
    "            if 'constant_value' not in locals():\n",
    "                print(\"Error: constant_value must be provided when strategy is 'constant'.\")\n",
    "                return None\n",
    "            df_imputed[col] = df_imputed[col].fillna(constant_value)\n",
    "\n",
    "    return df_imputed\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the missing data imputation and print the results.\n",
    "    \"\"\"\n",
    "    # Provide the path to your CSV file\n",
    "    csv_file = 'data_with_missing.csv'  # Replace with your actual file path\n",
    "\n",
    "    # Create a dummy CSV file with missing values for demonstration\n",
    "    try:\n",
    "        with open(csv_file, 'w') as f:\n",
    "            f.write(\"col1,col2,col3,col4\\n1,4,7,a\\n2,,8,b\\n3,5,,c\\n,6,9,d\\n5,,10,e\")\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "\n",
    "    # Impute missing values using the mean for col1, col2 and col3\n",
    "    imputed_df = handle_missing_data(csv_file, strategy='mean', columns_to_impute=['col1', 'col2', 'col3'])\n",
    "\n",
    "    # Print the results\n",
    "    if imputed_df is not None:\n",
    "        print(\"DataFrame with Imputed Values (Mean Imputation for col1, col2, col3):\")\n",
    "        print(imputed_df)\n",
    "\n",
    "    # Impute missing values of col3 using median\n",
    "    imputed_df = handle_missing_data(csv_file, strategy='median', columns_to_impute=['col3'])\n",
    "    if imputed_df is not None:\n",
    "        print(\"\\nDataFrame with Imputed Values (Median Imputation for col3):\")\n",
    "        print(imputed_df)\n",
    "\n",
    "    # Impute missing values of col1 and col2 using a constant value\n",
    "    imputed_df = handle_missing_data(csv_file, strategy='constant', columns_to_impute=['col1', 'col2'], constant_value=0)\n",
    "    if imputed_df is not None:\n",
    "        print(\"\\nDataFrame with Imputed Values (Constant Imputation (0) for col1 and col2):\")\n",
    "        print(imputed_df)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 7: Detect Duplicates\n",
    "\n",
    "Description: Detect duplicate rows in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows found:\n",
      " col1  col2  col3\n",
      "    1     4     7\n",
      "    2     5     8\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def detect_duplicate_rows(csv_file):\n",
    "    \"\"\"\n",
    "    Detects duplicate rows in a dataset.\n",
    "\n",
    "    Args:\n",
    "        csv_file (str): Path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame containing all duplicate rows, or an empty DataFrame if no duplicates are found.\n",
    "                          Returns None if an error occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the CSV file into a Pandas DataFrame\n",
    "        df = pd.read_csv(csv_file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {csv_file}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading CSV file: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Detect duplicate rows\n",
    "    duplicate_rows = df[df.duplicated(keep='first')]  # Get all duplicate rows, keeping the first occurrence\n",
    "\n",
    "    return duplicate_rows\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the duplicate row detection and print the results.\n",
    "    \"\"\"\n",
    "    # Provide the path to your CSV file\n",
    "    csv_file = 'data_with_duplicates.csv'  # Replace with your actual file path\n",
    "\n",
    "    # Create a dummy CSV file with duplicate rows for demonstration\n",
    "    try:\n",
    "        with open(csv_file, 'w') as f:\n",
    "            f.write(\"col1,col2,col3\\n1,4,7\\n2,5,8\\n1,4,7\\n3,6,9\\n2,5,8\\n4,7,10\\n\")\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "\n",
    "    # Detect duplicate rows\n",
    "    duplicate_rows_df = detect_duplicate_rows(csv_file)\n",
    "\n",
    "    # Print the results\n",
    "    if duplicate_rows_df is not None:\n",
    "        if duplicate_rows_df.empty:\n",
    "            print(\"No duplicate rows found in the dataset.\")\n",
    "        else:\n",
    "            print(\"Duplicate rows found:\")\n",
    "            print(duplicate_rows_df.to_string(index=False))\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 8: Validate Correctness of Numerical Values\n",
    "\n",
    "Description: Ensure numerical columns are within a specified range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Invalid range values for column 'price'.  Min and max must be numbers.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def validate_numerical_range(csv_file, column_ranges):\n",
    "    \"\"\"\n",
    "    Validates that numerical values in specified columns of a dataset are within defined ranges.\n",
    "\n",
    "    Args:\n",
    "        csv_file (str): Path to the CSV file.\n",
    "        column_ranges (dict): A dictionary where keys are column names and values are tuples\n",
    "            representing the minimum and maximum allowed values (inclusive) for that column.\n",
    "            For example: {'age': (0, 120), 'salary': (0, 1000000)}.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are column names, and values are DataFrames.\n",
    "            Each DataFrame contains the rows where the values in that column are outside the\n",
    "            specified range.  If a column is not found or has no values outside the range,\n",
    "            the column will not be included in the returned dictionary.\n",
    "            Returns None if there are errors.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the CSV file into a Pandas DataFrame\n",
    "        df = pd.read_csv(csv_file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {csv_file}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading CSV file: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Check for invalid input in column_ranges\n",
    "    for column, value_range in column_ranges.items():\n",
    "        if not isinstance(value_range, tuple) or len(value_range) != 2:\n",
    "            print(f\"Error: Invalid range format for column '{column}'.  Must be a tuple of (min, max).\")\n",
    "            return None\n",
    "        if not (isinstance(value_range[0], (int, float)) and isinstance(value_range[1], (int, float))):\n",
    "            print(f\"Error: Invalid range values for column '{column}'.  Min and max must be numbers.\")\n",
    "            return None\n",
    "\n",
    "    results = {}\n",
    "    for column, (min_val, max_val) in column_ranges.items():\n",
    "        if column not in df.columns:\n",
    "            print(f\"Error: Column '{column}' not found in the file.\")\n",
    "            continue  # Skip to the next column\n",
    "        if not pd.api.types.is_numeric_dtype(df[column]):\n",
    "            print(f\"Warning: Column '{column}' is not numeric and will be skipped.\")\n",
    "            continue\n",
    "\n",
    "        # Find values outside the range\n",
    "        out_of_range_rows = df[(df[column] < min_val) | (df[column] > max_val)]\n",
    "        if not out_of_range_rows.empty:\n",
    "            results[column] = out_of_range_rows\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the numerical value range check and print the results.\n",
    "    \"\"\"\n",
    "    # Provide the path to your CSV file\n",
    "    csv_file = 'data_with_numerical_outliers.csv'  # Replace with your actual file path\n",
    "\n",
    "    # Define the valid ranges for numerical columns\n",
    "    column_ranges = {\n",
    "        'age': (0, 120),\n",
    "        'salary': (0, 100000),\n",
    "        'height': (100, 250),  # Example in cm\n",
    "        'grade': (0, 100),\n",
    "        'price': (0, None) #Example with only a minimum\n",
    "    }\n",
    "\n",
    "    # Create a dummy CSV file for demonstration\n",
    "    try:\n",
    "        with open(csv_file, 'w') as f:\n",
    "            f.write(\"name,age,salary,height,grade,price\\nAlice,30,50000,150,80,200\\nBob,150,60000,180,90,1000\\nCharlie,25,75000,160,70,50\\nDavid,-5,100000,170,105,0\\nEve,80,200000,165,60,-10\\nFrank,60,55000,260,85,\\n\")\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "\n",
    "    # Validate numerical ranges\n",
    "    results = validate_numerical_range(csv_file, column_ranges)\n",
    "\n",
    "    # Print the results\n",
    "    if results is not None:\n",
    "        if not results:\n",
    "            print(\"No numerical values found outside the specified ranges.\")\n",
    "        else:\n",
    "            print(\"Numerical values found outside the specified ranges:\")\n",
    "            for column, out_of_range_df in results.items():\n",
    "                print(f\"\\nColumn: {column}\")\n",
    "                print(out_of_range_df.to_string(index=False))\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 9: Custom Completeness Rule Violation Report\n",
    "\n",
    "Description: Create a report showing which rows violate specific completeness rules, such as mandatory fields being empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completeness rule violations found:\n",
      " customer_id    name               email    phone     address        city\n",
      "           2     Bob                 NaN 555-5678         NaN Los Angeles\n",
      "           3 Charlie charlie@example.com      NaN 789 Pine Ln         NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def check_completeness_rules(csv_file, completeness_rules):\n",
    "    \"\"\"\n",
    "    Checks which rows in a dataset violate specified completeness rules.\n",
    "\n",
    "    Args:\n",
    "        csv_file (str): Path to the CSV file.\n",
    "        completeness_rules (dict): A dictionary where keys are column names and values are\n",
    "            booleans indicating whether the column is mandatory (True) or optional (False).\n",
    "            For example: {'customer_id': True, 'name': True, 'email': True, 'phone': False}.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame containing the rows that violate the completeness rules,\n",
    "                          or an empty DataFrame if no violations are found.\n",
    "                          Returns None if there are errors.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the CSV file into a Pandas DataFrame\n",
    "        df = pd.read_csv(csv_file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {csv_file}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading CSV file: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Check for invalid input in completeness_rules\n",
    "    for column, is_mandatory in completeness_rules.items():\n",
    "        if not isinstance(is_mandatory, bool):\n",
    "            print(f\"Error: Invalid value type for column '{column}'.  Must be a boolean.\")\n",
    "            return None\n",
    "\n",
    "    # Check if all mandatory columns exist\n",
    "    for column, is_mandatory in completeness_rules.items():\n",
    "        if is_mandatory and column not in df.columns:\n",
    "            print(f\"Error: Mandatory column '{column}' not found in the file.\")\n",
    "            return None\n",
    "\n",
    "    # Identify rows that violate completeness rules\n",
    "    violations = pd.DataFrame()  # Start with an empty DataFrame\n",
    "    for column, is_mandatory in completeness_rules.items():\n",
    "        if is_mandatory:\n",
    "            missing_values = df[column].isnull()\n",
    "            if missing_values.any():  # Check if there are any True values (missing values)\n",
    "                violations_df = df[missing_values] # get the rows where there are missing values\n",
    "                violations = pd.concat([violations, violations_df], ignore_index=True)\n",
    "\n",
    "    return violations\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the completeness rule violation check and print the results.\n",
    "    \"\"\"\n",
    "    # Provide the path to your CSV file\n",
    "    csv_file = 'customer_data_completeness.csv'  # Replace with your actual file path\n",
    "\n",
    "    # Define the completeness rules\n",
    "    completeness_rules = {\n",
    "        'customer_id': True,  # Mandatory\n",
    "        'name': True,        # Mandatory\n",
    "        'email': True,       # Mandatory\n",
    "        'phone': False,      # Optional\n",
    "        'address': False,    # Optional\n",
    "        'city': True\n",
    "    }\n",
    "\n",
    "    # Create a dummy CSV file for demonstration\n",
    "    try:\n",
    "        with open(csv_file, 'w') as f:\n",
    "            f.write(\"customer_id,name,email,phone,address,city\\n1,Alice,alice@example.com,555-1234,123 Main St,New York\\n2,Bob,,555-5678,,Los Angeles\\n3,Charlie,charlie@example.com,,789 Pine Ln,\\n4,David,david@example.com,555-9012,222 Elm St,Houston\\n5,Eve,eve@example.com,555-2345,333 Oak Ave,Miami\")\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "\n",
    "    # Check for completeness rule violations\n",
    "    violations_df = check_completeness_rules(csv_file, completeness_rules)\n",
    "\n",
    "    # Print the results\n",
    "    if violations_df is not None:\n",
    "        if violations_df.empty:\n",
    "            print(\"No completeness rule violations found.\")\n",
    "        else:\n",
    "            print(\"Completeness rule violations found:\")\n",
    "            print(violations_df.to_string(index=False))\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 10: Advanced Regex for Data Validity Check\n",
    "\n",
    "Description: Check for validity with advanced regex patterns, such as validating complex fields with multi-level rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column: order_id (Order ID format: Three uppercase letters followed by a hyphen and three digits (e.g., ABC-123))\n",
      "  Valid values: ['ABC-123', 'XYZ-456', 'DEF-789', 'GHI-001', 'MNO-987']\n",
      "  Invalid values: ['JKL-a23']\n",
      "\n",
      "Column: email (Standard email format (e.g., user@example.com))\n",
      "  Valid values: ['user@example.com', 'another@test.org', 'user@sub.domain.com', 'first.last@domain.co.in']\n",
      "  Invalid values: ['invalid-email', 'missing@dotcom']\n",
      "\n",
      "Column: phone (North American phone format (e.g., 123-456-7890, (123) 456-7890, +1-123-456-7890 ext. 123))\n",
      "  Valid values: ['123-456-7890', '(123) 456-7890', '1234567890']\n",
      "  Invalid values: ['+1-123-456-7890 ext. 123', '123.456.7890', 'invalid-phone']\n",
      "\n",
      "Column: date (Date in YYYY-MM-DD format (e.g., 2023-10-27))\n",
      "  Valid values: ['2023-10-26', '2023-10-28', '2023-10-29', '2023-10-30']\n",
      "  Invalid values: ['2023/10/26', '26.10.2023']\n",
      "\n",
      "Column: product_code (Product code: Two uppercase letters, hyphen, four digits, hyphen, and either one or two letters OR one to three digits (e.g., AB-1234-X, AB-1234-123))\n",
      "  Valid values: ['AB-1234-XY', 'AB-1234-12', 'AB-1234-123']\n",
      "  Invalid values: ['A-1234-X', 'AB-123-12', 'AB-1234-XYZ']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def validate_data_with_regex(csv_file, validation_rules):\n",
    "    \"\"\"\n",
    "    Validates data in a dataset using advanced regular expression patterns.\n",
    "\n",
    "    Args:\n",
    "        csv_file (str): Path to the CSV file.\n",
    "        validation_rules (dict): A dictionary where keys are column names and values are\n",
    "            dictionaries containing regex patterns and descriptions for validation.\n",
    "            For example:\n",
    "            {\n",
    "                'order_id': {'pattern': r'^[A-Z]{3}-\\d{3}$', 'description': 'e.g., ABC-123'},\n",
    "                'email': {'pattern': r\"^[^\\s@]+@[^\\s@]+\\.[^\\s@]{2,}$\", 'description': 'Standard email format'},\n",
    "                'phone': {\n",
    "                    'pattern': r\"^(?:\\+?\\d{1,3}[- ]?)?(?:\\(\\d{3}\\)[- ]?)?\\d{3}[- ]?\\d{4}$\",\n",
    "                    'description': 'North American phone format'\n",
    "                },\n",
    "                'date': {\n",
    "                    'pattern': r\"^\\d{4}-\\d{2}-\\d{2}$\",\n",
    "                    'description': 'YYYY-MM-DD'\n",
    "                }\n",
    "            }.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are column names from the validation_rules.\n",
    "              Values are dictionaries with keys 'valid' and 'invalid'.\n",
    "              'valid' contains the valid values from that column, and 'invalid' contains the invalid values.\n",
    "              Returns None if there are errors.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the CSV file into a Pandas DataFrame\n",
    "        df = pd.read_csv(csv_file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {csv_file}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading CSV file: {e}\")\n",
    "        return None\n",
    "\n",
    "    results = {}\n",
    "    for column, rule in validation_rules.items():\n",
    "        if column not in df.columns:\n",
    "            print(f\"Error: Column '{column}' not found in the file.\")\n",
    "            return None\n",
    "\n",
    "        pattern = rule.get('pattern')\n",
    "        description = rule.get('description', 'No description provided')  # Default description\n",
    "\n",
    "        if not pattern:\n",
    "            print(f\"Error: No regex pattern provided for column '{column}'.\")\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            # Apply the regex pattern to validate the column\n",
    "            valid_values = df[column][df[column].str.match(pattern, na=False)]  # na=False: important\n",
    "            invalid_values = df[column][~df[column].str.match(pattern, na=False)]\n",
    "            results[column] = {'valid': valid_values.tolist(), 'invalid': invalid_values.tolist()}\n",
    "        except re.error as e:\n",
    "            print(f\"Error: Invalid regular expression for column '{column}': {e}\")\n",
    "            return None\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the advanced regex data validation and print the results.\n",
    "    \"\"\"\n",
    "    # Provide the path to your CSV file\n",
    "    csv_file = 'data_for_validation.csv'  # Replace with your actual file path\n",
    "\n",
    "    # Define the validation rules with advanced regex patterns\n",
    "    validation_rules = {\n",
    "        'order_id': {\n",
    "            'pattern': r'^[A-Z]{3}-\\d{3}$',\n",
    "            'description': 'Order ID format: Three uppercase letters followed by a hyphen and three digits (e.g., ABC-123)'\n",
    "        },\n",
    "        'email': {\n",
    "            'pattern': r\"^[^\\s@]+@[^\\s@]+\\.[^\\s@]{2,}$\",\n",
    "            'description': 'Standard email format (e.g., user@example.com)'\n",
    "        },\n",
    "        'phone': {\n",
    "            'pattern': r\"^(?:\\+?\\d{1,3}[- ]?)?(?:\\(\\d{3}\\)[- ]?)?\\d{3}[- ]?\\d{4}(?:(?: ext\\.)?\\s*\\d+)?$\",\n",
    "            'description': 'North American phone format (e.g., 123-456-7890, (123) 456-7890, +1-123-456-7890 ext. 123)'\n",
    "        },\n",
    "        'date': {\n",
    "            'pattern': r\"^\\d{4}-\\d{2}-\\d{2}$\",\n",
    "            'description': 'Date in YYYY-MM-DD format (e.g., 2023-10-27)'\n",
    "        },\n",
    "        'product_code': {\n",
    "            'pattern': r\"^[A-Z]{2}-\\d{4}-(?:[A-Z]{1,2}|\\d{1,3})$\",\n",
    "            'description': 'Product code: Two uppercase letters, hyphen, four digits, hyphen, and either one or two letters OR one to three digits (e.g., AB-1234-X, AB-1234-123)'\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Create a dummy CSV file for demonstration\n",
    "    try:\n",
    "        with open(csv_file, 'w') as f:\n",
    "            f.write(\"order_id,email,phone,date,product_code\\nABC-123,user@example.com,123-456-7890,2023-10-26,AB-1234-XY\\nXYZ-456,invalid-email,(123) 456-7890,2023/10/26,AB-1234-12\\nDEF-789,another@test.org,+1-123-456-7890 ext. 123,26.10.2023,AB-1234-123\\nGHI-001,missing@dotcom,123.456.7890,2023-10-28,A-1234-X\\nJKL-a23,user@sub.domain.com,1234567890,2023-10-29,AB-123-12\\nMNO-987,first.last@domain.co.in,invalid-phone,2023-10-30,AB-1234-XYZ\\n\")\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "\n",
    "    # Validate data using advanced regex patterns\n",
    "    results = validate_data_with_regex(csv_file, validation_rules)\n",
    "\n",
    "    # Print the results\n",
    "    if results is not None:\n",
    "        for column, values in results.items():\n",
    "            print(f\"\\nColumn: {column} ({validation_rules[column]['description']})\")\n",
    "            print(f\"  Valid values: {values['valid']}\")\n",
    "            print(f\"  Invalid values: {values['invalid']}\")\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
