{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture to Monitor Data Quality Over Time\n",
    "\n",
    "**Description**: Design a monitoring system in Python that checks and logs data quality metrics (accuracy, completeness) for a dataset over time.\n",
    "\n",
    "**Steps to follow:**\n",
    "1. Implement a Scheduled Script:\n",
    "    - Use schedule library to periodically run a script.\n",
    "2. Script to Calculate Metrics:\n",
    "    - For simplicity, use a function calculate_quality_metrics() that calculates and logs metrics such as missing rate or mismatch rate.\n",
    "3. Store Logs:\n",
    "    - Use Python's logging library to save these metrics over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import time\n",
    "from datetime import datetime\n",
    "import sys\n",
    "\n",
    "# Logging setup\n",
    "logging.basicConfig(filename='data_quality_log.txt', level=logging.INFO,\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def calculate_quality_metrics(data_file, trusted_file=None):\n",
    "    \"\"\"\n",
    "    Calculates and logs data quality metrics (completeness and accuracy) for a given dataset.\n",
    "\n",
    "    Args:\n",
    "        data_file (str): Path to the CSV file containing the data to be checked.\n",
    "        trusted_file (str, optional): Path to the CSV file containing trusted data for accuracy checks.\n",
    "            If provided, accuracy is calculated; otherwise, only completeness is calculated.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(data_file)\n",
    "        logging.info(f\"Data file '{data_file}' loaded successfully.\")\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"Error: Data file '{data_file}' not found.\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error reading data file '{data_file}': {e}\")\n",
    "        return\n",
    "\n",
    "    total_rows = len(df)\n",
    "\n",
    "    # Calculate completeness for all columns\n",
    "    completeness = {}\n",
    "    for col in df.columns:\n",
    "        missing_count = df[col].isnull().sum()\n",
    "        completeness[col] = ((total_rows - missing_count) / total_rows) * 100\n",
    "        logging.info(f\"Completeness for column '{col}': {completeness[col]:.2f}%\")\n",
    "\n",
    "    # Calculate overall completeness\n",
    "    overall_completeness = df.dropna().shape[0] / total_rows * 100 if total_rows else 0\n",
    "    logging.info(f\"Overall Completeness: {overall_completeness:.2f}%\")\n",
    "\n",
    "    if trusted_file:\n",
    "        try:\n",
    "            trusted_df = pd.read_csv(trusted_file)\n",
    "            logging.info(f\"Trusted data file '{trusted_file}' loaded successfully.\")\n",
    "        except FileNotFoundError:\n",
    "            logging.error(f\"Error: Trusted data file '{trusted_file}' not found. Skipping accuracy check.\")\n",
    "            return\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error reading trusted data file '{trusted_file}': {e}. Skipping accuracy check.\")\n",
    "            return\n",
    "\n",
    "        # Check for common columns\n",
    "        common_columns = list(set(df.columns) & set(trusted_df.columns))\n",
    "        if not common_columns:\n",
    "            logging.error(\"Error: No common columns between data and trusted data files. Skipping accuracy check.\")\n",
    "            return\n",
    "\n",
    "        # Calculate accuracy for common columns\n",
    "        accuracy = {}\n",
    "        for col in common_columns:\n",
    "            if df[col].dtype == trusted_df[col].dtype:  # Compare values only if types match\n",
    "                match_count = (df[col] == trusted_df[col]).sum()\n",
    "                accuracy[col] = (match_count / total_rows) * 100 if total_rows else 0\n",
    "                logging.info(f\"Accuracy for column '{col}': {accuracy[col]:.2f}%\")\n",
    "            else:\n",
    "                logging.warning(f\"Skipping accuracy check for column '{col}' as data types differ.\")\n",
    "                accuracy[col] = None  # Explicitly set to None for skipped columns\n",
    "        #Calculate overall accuracy\n",
    "        valid_accuracy_values = [a for a in accuracy.values() if a is not None] #skipping None values\n",
    "        overall_accuracy = np.mean(valid_accuracy_values) if valid_accuracy_values else 0\n",
    "        logging.info(f\"Overall Accuracy: {overall_accuracy:.2f}%\")\n",
    "\n",
    "    logging.info(\"Data quality check completed.\")\n",
    "\n",
    "\n",
    "\n",
    "def run_data_quality_check():\n",
    "    \"\"\"\n",
    "    Runs the data quality check and logs the metrics.  This function is called by the scheduler.\n",
    "    \"\"\"\n",
    "    #  Replace 'your_data.csv' and 'your_trusted_data.csv' with your actual file paths\n",
    "    data_file = 'sales_data.csv'\n",
    "    trusted_file = 'trusted_sales_data.csv'  # Optional:  Only if you have trusted data\n",
    "\n",
    "    # Create dummy CSV files if they don't exist\n",
    "    try:\n",
    "        with open(data_file, 'w') as f:\n",
    "            f.write(\"order_id,customer_id,order_date,amount,status\\n1,101,2024-01-15,100.0,Shipped\\n2,102,2024-01-20,150.0,Shipped\\n3,103,2024-02-10,,Pending\\n4,104,2024-02-25,200.0,Shipped\\n5,105,2024-03-05,250.0,Delivered\")\n",
    "        if trusted_file:\n",
    "            with open(trusted_file, 'w') as f:\n",
    "                f.write(\"order_id,customer_id,order_date,amount,status\\n1,101,2024-01-15,100.0,Shipped\\n2,102,2024-01-20,150.0,Shipped\\n3,103,2024-02-10,120.0,Pending\\n4,104,2024-02-25,200.0,Shipped\\n5,105,2024-03-05,250.0,Delivered\")\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "\n",
    "    calculate_quality_metrics(data_file, trusted_file)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Schedule the data quality check to run daily at 00:00\n",
    "    # schedule.every().day.at(\"00:00\").do(run_data_quality_check)\n",
    "    # logging.info(\"Data quality monitoring scheduled to run daily at 00:00.\")\n",
    "    #\n",
    "    # # Keep the script running to allow the scheduler to do its work\n",
    "    # while True:\n",
    "    #     schedule.run_pending()\n",
    "    #     time.sleep(1)\n",
    "    run_data_quality_check() # run once\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
