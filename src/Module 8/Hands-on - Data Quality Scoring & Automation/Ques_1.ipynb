{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Understanding and Defining Data Quality Metrics\n",
    "**Description**: Learn how to define basic data quality metrics such as completeness, validity, and uniqueness for a simple dataset.\n",
    "\n",
    "**Steps**:\n",
    "1. Dataset: Use a CSV with columns like Name , Email , Age .\n",
    "2. Metric Definitions:\n",
    "    - Completeness: Percentage of non-null values.\n",
    "    - Validity: % of email fields containing @ .\n",
    "    - Uniqueness: Count distinct entries in the Email column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas_profiling'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas_profiling\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mge\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExpectationSuite, ExpectationConfiguration\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas_profiling'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import great_expectations as ge\n",
    "from great_expectations.core import ExpectationSuite, ExpectationConfiguration\n",
    "import streamlit as st\n",
    "import logging\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "import datetime\n",
    "import time\n",
    "import threading\n",
    "import random\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import numpy as np\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # Set the logging level (e.g., INFO, WARNING, ERROR)\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[logging.StreamHandler()],  # Output to the console\n",
    ")\n",
    "logger = logging.getLogger(__name__)  # Get the logger for this module\n",
    "\n",
    "\n",
    "def profile_data_with_pandas_profiling(file_path):\n",
    "    \"\"\"\n",
    "    Profiles data from a CSV file using Pandas-Profiling.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the CSV file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1. Load the CSV file into a Pandas DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        st.write(f\"Loaded data from: {file_path}\")\n",
    "\n",
    "        # 2. Generate a profile report with default settings\n",
    "        profile = pandas_profiling.ProfileReport(df, title=\"Pandas Profiling Report\")\n",
    "\n",
    "        # Save the report\n",
    "        profile_file_name = file_path.replace(\".csv\", \"_profile.html\")\n",
    "        profile.to_file(profile_file_name)\n",
    "        st.success(f\"Pandas-Profiling report generated and saved to: {profile_file_name}\")\n",
    "\n",
    "        # Display the report in Streamlit\n",
    "        st.header(\"Pandas Profiling Report\")\n",
    "        st.components.v1.html(profile.to_html(), width=800, height=600, scrolling=True)\n",
    "\n",
    "        # 3. Customize the profile report to include correlations and a subset of columns\n",
    "        # Calculate correlations (e.g., Pearson correlation)\n",
    "        profile_with_corr = pandas_profiling.ProfileReport(\n",
    "            df,\n",
    "            title=\"Pandas Profiling Report with Correlations\",\n",
    "            explorative=True,  # Enable more detailed exploration\n",
    "            correlations={\"pearson\": {\"calculate\": True}},  # Calculate Pearson correlation\n",
    "        )\n",
    "\n",
    "        # Save the report with correlations\n",
    "        profile_with_corr_filename = file_path.replace(\".csv\", \"_profile_with_corr.html\")\n",
    "        profile_with_corr.to_file(profile_with_corr_filename)\n",
    "        st.success(f\"Pandas-Profiling report with correlations generated and saved to: {profile_with_corr_filename}\")\n",
    "\n",
    "        # Profile a subset of columns\n",
    "        if 'age' in df.columns and 'income' in df.columns:  # Check if the columns exist\n",
    "            subset_profile = pandas_profiling.ProfileReport(\n",
    "                df[['age', 'income']],  # Profile only 'age' and 'income'\n",
    "                title=\"Pandas Profiling Report - Subset of Columns\",\n",
    "            )\n",
    "            subset_profile_filename = file_path.replace(\".csv\", \"_profile_subset.html\")\n",
    "            subset_profile.to_file(subset_profile_filename)\n",
    "            st.success(f\"Pandas-Profiling report for subset of columns generated and saved to: {subset_profile_filename}\")\n",
    "        else:\n",
    "            st.warning(\"Columns 'age' and 'income' not found in the DataFrame.  Skipping subset profiling.\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        st.error(f\"Error: File not found at {file_path}\")\n",
    "    except Exception as e:\n",
    "        st.error(f\"An error occurred: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "def profile_data_with_great_expectations(file_path):\n",
    "    \"\"\"\n",
    "    Profiles data from a CSV file using Great Expectations.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the CSV file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the CSV file into a Pandas DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        st.write(f\"Loaded data from: {file_path}\")\n",
    "\n",
    "        # Create a Great Expectations context\n",
    "        context = ge.get_context()\n",
    "\n",
    "        # Create an expectation suite (or load an existing one)\n",
    "        expectation_suite_name = \"my_data_suite\"  # You can choose any name\n",
    "        suite = context.get_expectation_suite(expectation_suite_name)\n",
    "        if suite is None:\n",
    "            suite = context.create_expectation_suite(expectation_suite_name)\n",
    "\n",
    "        # Add multiple expectations to the suite\n",
    "        suite.add_expectation(\n",
    "            ge.core.ExpectationConfiguration(  # Use ge.core.ExpectationConfiguration\n",
    "                expectation_type=\"expect_table_columns_to_exist\",\n",
    "                kwargs={\"column_names\": df.columns.tolist()},\n",
    "            )\n",
    "        )\n",
    "        if 'age' in df.columns:\n",
    "            suite.add_expectation(\n",
    "                ge.core.ExpectationConfiguration(  # Use ge.core.ExpectationConfiguration\n",
    "                    expectation_type=\"expect_column_values_to_be_between\",\n",
    "                    kwargs={\n",
    "                        \"column\": \"age\",\n",
    "                        \"min_value\": 0,\n",
    "                        \"max_value\": 150,\n",
    "                    },\n",
    "                )\n",
    "            )\n",
    "        if 'income' in df.columns:\n",
    "            suite.add_expectation(\n",
    "                ge.core.ExpectationConfiguration(  # Use ge.core.ExpectationConfiguration\n",
    "                    expectation_type=\"expect_column_values_to_not_be_null\",\n",
    "                    kwargs={\"column\": \"income\"},\n",
    "                )\n",
    "            )\n",
    "\n",
    "        context.save_expectation_suite(suite, expectation_suite_name=expectation_suite_name) #save the suite\n",
    "\n",
    "        # Create a BatchRequest\n",
    "        batch_request = ge.datasource.Datasource.create_batch_request(\n",
    "            datasource_name=\"pandas\",  # Use the name 'pandas'\n",
    "            data_asset_name=\"my_data\",  # You can choose any name\n",
    "            pandas_df=df,  # Pass the DataFrame here\n",
    "        )\n",
    "\n",
    "        # 4. Validate data against the expectation suite\n",
    "        validator = context.get_validator(\n",
    "            batch_request=batch_request,\n",
    "            expectation_suite_name=expectation_suite_name,\n",
    "        )\n",
    "        validation_results = validator.validate()\n",
    "\n",
    "        # Print the validation results\n",
    "        st.header(\"Great Expectations Validation Results\")\n",
    "        st.json(validation_results)\n",
    "\n",
    "        # 5. Check if the validation was successful\n",
    "        if validation_results[\"success\"]:\n",
    "            st.success(\"Data validation with Great Expectations was successful!\")\n",
    "            return True  # Return True for success\n",
    "        else:\n",
    "            st.error(\"Data validation with Great Expectations failed!\")\n",
    "            return False  # Return False for failure\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        st.error(f\"Error: File not found at {file_path}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        st.error(f\"An error occurred: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "def send_email_alert(subject, body):\n",
    "    \"\"\"\n",
    "    Sends an email alert.\n",
    "\n",
    "    Args:\n",
    "        subject (str): The subject of the email.\n",
    "        body (str): The body of the email.\n",
    "    \"\"\"\n",
    "    sender_email = \"your_email@example.com\"  # Replace with your email address\n",
    "    receiver_email = \"recipient_email@example.com\"  # Replace with the recipient's email address\n",
    "    smtp_server = \"smtp.example.com\"  # Replace with your SMTP server address\n",
    "    smtp_port = 587  # Replace with your SMTP server port (e.g., 587 for TLS)\n",
    "    smtp_username = \"your_email@example.com\"  # Replace with your email username\n",
    "    smtp_password = \"your_email_password\"  # Replace with your email password or an app password\n",
    "\n",
    "    msg = MIMEText(body)\n",
    "    msg[\"Subject\"] = subject\n",
    "    msg[\"From\"] = sender_email\n",
    "    msg[\"To\"] = receiver_email\n",
    "\n",
    "    try:\n",
    "        server = smtplib.SMTP(smtp_server, smtp_port)\n",
    "        server.starttls()\n",
    "        server.login(smtp_username, smtp_password)\n",
    "        server.sendmail(sender_email, [receiver_email], msg.as_string())\n",
    "        server.quit()\n",
    "        logger.info(\"Email alert sent successfully.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error sending email alert: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "def detect_anomalies(df):\n",
    "    \"\"\"\n",
    "    Detects anomalies in the given DataFrame using Isolation Forest.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the detected anomalies, or an empty DataFrame if no anomalies are found.\n",
    "    \"\"\"\n",
    "    # Handle missing values using imputation (replace NaN with the mean of the column)\n",
    "    df_imputed = df.copy()  # Create a copy to avoid modifying the original DataFrame\n",
    "    for col in df_imputed.columns:\n",
    "        if df_imputed[col].isnull().any():\n",
    "            mean_val = df_imputed[col].mean()\n",
    "            df_imputed[col] = df_imputed[col].fillna(mean_val)\n",
    "\n",
    "    # Initialize and fit the Isolation Forest model\n",
    "    model = IsolationForest(contamination='auto', random_state=42)  # Set random_state for reproducibility\n",
    "    model.fit(df_imputed)\n",
    "\n",
    "    # Predict anomalies (returns 1 for inliers, -1 for outliers)\n",
    "    anomaly_labels = model.predict(df_imputed)\n",
    "\n",
    "    # Get the anomaly data points\n",
    "    anomaly_data = df[anomaly_labels == -1]\n",
    "    return anomaly_data\n",
    "\n",
    "\n",
    "\n",
    "def calculate_data_quality_metrics(df):\n",
    "    \"\"\"\n",
    "    Calculates data quality metrics for the given DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame with columns 'Name', 'Email', and 'Age'.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the calculated metrics:\n",
    "            - completeness (dict): Completeness for each column.\n",
    "            - validity (dict): Validity for the 'Email' column.\n",
    "            - uniqueness (int): Uniqueness of the 'Email' column.\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "\n",
    "    # Completeness: Percentage of non-null values for each column\n",
    "    completeness = {}\n",
    "    for col in df.columns:\n",
    "        completeness[col] = df[col].count() / len(df) if len(df) > 0 else 0\n",
    "    metrics['completeness'] = completeness\n",
    "\n",
    "    # Validity: Percentage of email fields containing '@'\n",
    "    if 'Email' in df.columns:\n",
    "        valid_emails = df['Email'].astype(str).str.contains('@').sum()\n",
    "        validity = (valid_emails / len(df)) if len(df) > 0 else 0\n",
    "        metrics['validity'] = {'Email': validity}\n",
    "    else:\n",
    "        metrics['validity'] = {'Email': None}\n",
    "\n",
    "    # Uniqueness: Count distinct entries in the Email column\n",
    "    if 'Email' in df.columns:\n",
    "        uniqueness = df['Email'].nunique()\n",
    "        metrics['uniqueness'] = uniqueness\n",
    "    else:\n",
    "        metrics['uniqueness'] = None\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "\n",
    "def monitor_data_quality(file_path):\n",
    "    \"\"\"\n",
    "    Monitors data quality in real-time (simulated) by repeatedly profiling\n",
    "    data with Great Expectations and using AI (Isolation Forest) to detect anomalies.\n",
    "    Sends alerts if quality drops or anomalies are detected. Also calculates and logs\n",
    "    data quality metrics.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the CSV file.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        # Simulate data updates\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            # Introduce random changes\n",
    "            if random.random() < 0.2:\n",
    "                if 'age' in df.columns:\n",
    "                    df['age'] = df['age'].apply(lambda x: x + random.randint(-5, 5))\n",
    "                if 'income' in df.columns:\n",
    "                    df['income'] = df['income'].apply(lambda x: x * (1 + random.uniform(-0.1, 0.1)) if pd.notnull(x) else None)\n",
    "                if 'Email' in df.columns:\n",
    "                    df['Email'] = df['Email'].apply(lambda x: f\"invalid_{x}\" if random.random() < 0.1 and isinstance(x, str) else x) # 10% chance of invalidating\n",
    "            df.to_csv(file_path, index=False)\n",
    "            logger.info(f\"Simulated data update at {datetime.datetime.now()}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error reading or updating data: {e}\")\n",
    "            continue  # Go to the next iteration of the loop\n",
    "\n",
    "        # 1. Basic AI Models for Monitoring\n",
    "        #   - Train a simple anomaly detection model using Isolation Forest.\n",
    "        anomaly_data = detect_anomalies(df)\n",
    "\n",
    "        # 2. Use a simple custom function based AI logic for outlier detection.\n",
    "        #    (Example: check if age is outside of expected range)\n",
    "        anomalous_age_data = df[(df['age'] < 0) | (df['age'] > 120)] #0-120\n",
    "        if not anomalous_age_data.empty:\n",
    "            logger.warning(f\"Outliers detected in 'age' column: {anomalous_age_data.to_string()}\")\n",
    "\n",
    "        # Profile data with Great Expectations\n",
    "        validation_status = profile_data_with_great_expectations(file_path)\n",
    "\n",
    "        # 3. Creating a monitoring function that utilizes a pre-trained machine learning model.\n",
    "        #    (This is already happening with the use of detect_anomalies)\n",
    "\n",
    "        # Calculate and log data quality metrics\n",
    "        metrics = calculate_data_quality_metrics(df)\n",
    "        logger.info(f\"Data Quality Metrics: {metrics}\")\n",
    "\n",
    "        if not validation_status or not anomaly_data.empty or not anomalous_age_data.empty: #send if GE validation fails or anomalies detected\n",
    "            subject = \"Data Quality and Anomaly Alert\"\n",
    "            body = f\"Data quality check failed at {datetime.datetime.now()}.  Please investigate the data in {file_path}.\"\n",
    "            if not validation_status:\n",
    "                body += \"\\n\\nGreat Expectations validation failed.\"\n",
    "            if not anomaly_data.empty:\n",
    "                body += \"\\n\\nAnomalies detected by Isolation Forest:\\n\"\n",
    "                body += anomaly_data.to_string()\n",
    "            if not anomalous_age_data.empty:\n",
    "                body += \"\\n\\nAnomalies detected in age column:\\n\"\n",
    "                body += anomalous_age_data.to_string()\n",
    "            body += f\"\\n\\nData Quality Metrics: {metrics}\" #append the metrics to email\n",
    "            send_email_alert(subject, body)\n",
    "            logger.error(f\"Data quality check failed!\")\n",
    "        else:\n",
    "            logger.info(\"Data quality check successful.\")\n",
    "\n",
    "        time.sleep(60)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Get the file path from the user using st.text_input\n",
    "    default_file_path = \"data.csv\"  # Replace with your default CSV file name\n",
    "    file_path = st.text_input(\"Enter the path to your CSV file:\", default_file_path)\n",
    "\n",
    "    # Create a sample CSV file if it doesn't exist\n",
    "    if not pd.io.common.file_exists(file_path):\n",
    "        df = pd.DataFrame({\n",
    "            'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
    "            'Email': ['alice@example.com', 'bob@example.com', 'charlie@example.com', 'david.com', None],\n",
    "            'Age': [25, 30, 35, 40, 45]\n",
    "        })\n",
    "        df.to_csv(file_path, index=False)\n",
    "        st.info(f\"Created a sample CSV file at {file_path}.  You can replace this with your own data.\")\n",
    "\n",
    "    # Profile data with Pandas-Profiling\n",
    "    st.header(\"Data Profiling with Pandas-Profiling\")\n",
    "    profile_data_with_pandas_profiling(file_path)\n",
    "\n",
    "    # Profile data with Great Expectations\n",
    "    st.header(\"Data Profiling with Great Expectations\")\n",
    "    profile_data_with_great_expectations(file_path)\n",
    "\n",
    "    # Start real-time monitoring in a separate thread\n",
    "    monitoring_thread = threading.Thread(target=monitor_data_quality, args=(file_path,))\n",
    "    monitoring_thread.daemon = True  # Allow the main thread to exit\n",
    "    monitoring_thread.start()\n",
    "\n",
    "    st.subheader(\"Real-time Data Quality Monitoring\")\n",
    "    st.write(\"Data quality is being monitored in the background.  \"\n",
    "             \"Check the console for log messages and email alerts (if any issues are detected).\")\n",
    "\n",
    "    # Keep the main thread alive.\n",
    "    while True:\n",
    "        time.sleep(600)\n",
    "        st.info(\"The main thread is still alive. Monitoring is running in the background...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Calculating Data Quality Score\n",
    "**Description**: Aggregate multiple metrics to calculate an overall data quality score.\n",
    "\n",
    "**Steps**:\n",
    "1. Formula: Simple average of all metrics defined in Task 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas_profiling'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas_profiling\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mge\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExpectationSuite, ExpectationConfiguration\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas_profiling'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import great_expectations as ge\n",
    "from great_expectations.core import ExpectationSuite, ExpectationConfiguration\n",
    "import streamlit as st\n",
    "import logging\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "import datetime\n",
    "import time\n",
    "import threading\n",
    "import random\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import numpy as np\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # Set the logging level (e.g., INFO, WARNING, ERROR)\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[logging.StreamHandler()],  # Output to the console\n",
    ")\n",
    "logger = logging.getLogger(__name__)  # Get the logger for this module\n",
    "\n",
    "\n",
    "def profile_data_with_pandas_profiling(file_path):\n",
    "    \"\"\"\n",
    "    Profiles data from a CSV file using Pandas-Profiling.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the CSV file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1. Load the CSV file into a Pandas DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        st.write(f\"Loaded data from: {file_path}\")\n",
    "\n",
    "        # 2. Generate a profile report with default settings\n",
    "        profile = pandas_profiling.ProfileReport(df, title=\"Pandas Profiling Report\")\n",
    "\n",
    "        # Save the report\n",
    "        profile_file_name = file_path.replace(\".csv\", \"_profile.html\")\n",
    "        profile.to_file(profile_file_name)\n",
    "        st.success(f\"Pandas-Profiling report generated and saved to: {profile_file_name}\")\n",
    "\n",
    "        # Display the report in Streamlit\n",
    "        st.header(\"Pandas Profiling Report\")\n",
    "        st.components.v1.html(profile.to_html(), width=800, height=600, scrolling=True)\n",
    "\n",
    "        # 3. Customize the profile report to include correlations and a subset of columns\n",
    "        # Calculate correlations (e.g., Pearson correlation)\n",
    "        profile_with_corr = pandas_profiling.ProfileReport(\n",
    "            df,\n",
    "            title=\"Pandas Profiling Report with Correlations\",\n",
    "            explorative=True,  # Enable more detailed exploration\n",
    "            correlations={\"pearson\": {\"calculate\": True}},  # Calculate Pearson correlation\n",
    "        )\n",
    "\n",
    "        # Save the report with correlations\n",
    "        profile_with_corr_filename = file_path.replace(\".csv\", \"_profile_with_corr.html\")\n",
    "        profile_with_corr.to_file(profile_with_corr_filename)\n",
    "        st.success(f\"Pandas-Profiling report with correlations generated and saved to: {profile_with_corr_filename}\")\n",
    "\n",
    "        # Profile a subset of columns\n",
    "        if 'age' in df.columns and 'income' in df.columns:  # Check if the columns exist\n",
    "            subset_profile = pandas_profiling.ProfileReport(\n",
    "                df[['age', 'income']],  # Profile only 'age' and 'income'\n",
    "                title=\"Pandas Profiling Report - Subset of Columns\",\n",
    "            )\n",
    "            subset_profile_filename = file_path.replace(\".csv\", \"_profile_subset.html\")\n",
    "            subset_profile.to_file(subset_profile_filename)\n",
    "            st.success(f\"Pandas-Profiling report for subset of columns generated and saved to: {subset_profile_filename}\")\n",
    "        else:\n",
    "            st.warning(\"Columns 'age' and 'income' not found in the DataFrame.  Skipping subset profiling.\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        st.error(f\"Error: File not found at {file_path}\")\n",
    "    except Exception as e:\n",
    "        st.error(f\"An error occurred: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "def profile_data_with_great_expectations(file_path):\n",
    "    \"\"\"\n",
    "    Profiles data from a CSV file using Great Expectations.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the CSV file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the CSV file into a Pandas DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        st.write(f\"Loaded data from: {file_path}\")\n",
    "\n",
    "        # Create a Great Expectations context\n",
    "        context = ge.get_context()\n",
    "\n",
    "        # Create an expectation suite (or load an existing one)\n",
    "        expectation_suite_name = \"my_data_suite\"  # You can choose any name\n",
    "        suite = context.get_expectation_suite(expectation_suite_name)\n",
    "        if suite is None:\n",
    "            suite = context.create_expectation_suite(expectation_suite_name)\n",
    "\n",
    "        # Add multiple expectations to the suite\n",
    "        suite.add_expectation(\n",
    "            ge.core.ExpectationConfiguration(  # Use ge.core.ExpectationConfiguration\n",
    "                expectation_type=\"expect_table_columns_to_exist\",\n",
    "                kwargs={\"column_names\": df.columns.tolist()},\n",
    "            )\n",
    "        )\n",
    "        if 'age' in df.columns:\n",
    "            suite.add_expectation(\n",
    "                ge.core.ExpectationConfiguration(  # Use ge.core.ExpectationConfiguration\n",
    "                    expectation_type=\"expect_column_values_to_be_between\",\n",
    "                    kwargs={\n",
    "                        \"column\": \"age\",\n",
    "                        \"min_value\": 0,\n",
    "                        \"max_value\": 150,\n",
    "                    },\n",
    "                )\n",
    "            )\n",
    "        if 'income' in df.columns:\n",
    "            suite.add_expectation(\n",
    "                ge.core.ExpectationConfiguration(  # Use ge.core.ExpectationConfiguration\n",
    "                    expectation_type=\"expect_column_values_to_not_be_null\",\n",
    "                    kwargs={\"column\": \"income\"},\n",
    "                )\n",
    "            )\n",
    "\n",
    "        context.save_expectation_suite(suite, expectation_suite_name=expectation_suite_name) #save the suite\n",
    "\n",
    "        # Create a BatchRequest\n",
    "        batch_request = ge.datasource.Datasource.create_batch_request(\n",
    "            datasource_name=\"pandas\",  # Use the name 'pandas'\n",
    "            data_asset_name=\"my_data\",  # You can choose any name\n",
    "            pandas_df=df,  # Pass the DataFrame here\n",
    "        )\n",
    "\n",
    "        # 4. Validate data against the expectation suite\n",
    "        validator = context.get_validator(\n",
    "            batch_request=batch_request,\n",
    "            expectation_suite_name=expectation_suite_name,\n",
    "        )\n",
    "        validation_results = validator.validate()\n",
    "\n",
    "        # Print the validation results\n",
    "        st.header(\"Great Expectations Validation Results\")\n",
    "        st.json(validation_results)\n",
    "\n",
    "        # 5. Check if the validation was successful\n",
    "        if validation_results[\"success\"]:\n",
    "            st.success(\"Data validation with Great Expectations was successful!\")\n",
    "            return True  # Return True for success\n",
    "        else:\n",
    "            st.error(\"Data validation with Great Expectations failed!\")\n",
    "            return False  # Return False for failure\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        st.error(f\"Error: File not found at {file_path}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        st.error(f\"An error occurred: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "def send_email_alert(subject, body):\n",
    "    \"\"\"\n",
    "    Sends an email alert.\n",
    "\n",
    "    Args:\n",
    "        subject (str): The subject of the email.\n",
    "        body (str): The body of the email.\n",
    "    \"\"\"\n",
    "    sender_email = \"your_email@example.com\"  # Replace with your email address\n",
    "    receiver_email = \"recipient_email@example.com\"  # Replace with the recipient's email address\n",
    "    smtp_server = \"smtp.example.com\"  # Replace with your SMTP server address\n",
    "    smtp_port = 587  # Replace with your SMTP server port (e.g., 587 for TLS)\n",
    "    smtp_username = \"your_email@example.com\"  # Replace with your email username\n",
    "    smtp_password = \"your_email_password\"  # Replace with your email password or an app password\n",
    "\n",
    "    msg = MIMEText(body)\n",
    "    msg[\"Subject\"] = subject\n",
    "    msg[\"From\"] = sender_email\n",
    "    msg[\"To\"] = receiver_email\n",
    "\n",
    "    try:\n",
    "        server = smtplib.SMTP(smtp_server, smtp_port)\n",
    "        server.starttls()\n",
    "        server.login(smtp_username, smtp_password)\n",
    "        server.sendmail(sender_email, [receiver_email], msg.as_string())\n",
    "        server.quit()\n",
    "        logger.info(\"Email alert sent successfully.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error sending email alert: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "def detect_anomalies(df):\n",
    "    \"\"\"\n",
    "    Detects anomalies in the given DataFrame using Isolation Forest.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the detected anomalies, or an empty DataFrame if no anomalies are found.\n",
    "    \"\"\"\n",
    "    # Handle missing values using imputation (replace NaN with the mean of the column)\n",
    "    df_imputed = df.copy()  # Create a copy to avoid modifying the original DataFrame\n",
    "    for col in df_imputed.columns:\n",
    "        if df_imputed[col].isnull().any():\n",
    "            mean_val = df_imputed[col].mean()\n",
    "            df_imputed[col] = df_imputed[col].fillna(mean_val)\n",
    "\n",
    "    # Initialize and fit the Isolation Forest model\n",
    "    model = IsolationForest(contamination='auto', random_state=42)  # Set random_state for reproducibility\n",
    "    model.fit(df_imputed)\n",
    "\n",
    "    # Predict anomalies (returns 1 for inliers, -1 for outliers)\n",
    "    anomaly_labels = model.predict(df_imputed)\n",
    "\n",
    "    # Get the anomaly data points\n",
    "    anomaly_data = df[anomaly_labels == -1]\n",
    "    return anomaly_data\n",
    "\n",
    "\n",
    "\n",
    "def calculate_data_quality_metrics(df):\n",
    "    \"\"\"\n",
    "    Calculates data quality metrics for the given DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame with columns 'Name', 'Email', and 'Age'.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the calculated metrics:\n",
    "            - completeness (dict): Completeness for each column.\n",
    "            - validity (dict): Validity for the 'Email' column.\n",
    "            - uniqueness (int): Uniqueness of the 'Email' column.\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "\n",
    "    # Completeness: Percentage of non-null values for each column\n",
    "    completeness = {}\n",
    "    for col in df.columns:\n",
    "        completeness[col] = df[col].count() / len(df) if len(df) > 0 else 0\n",
    "    metrics['completeness'] = completeness\n",
    "\n",
    "    # Validity: Percentage of email fields containing '@'\n",
    "    if 'Email' in df.columns:\n",
    "        valid_emails = df['Email'].astype(str).str.contains('@').sum()\n",
    "        validity = (valid_emails / len(df)) if len(df) > 0 else 0\n",
    "        metrics['validity'] = {'Email': validity}\n",
    "    else:\n",
    "        metrics['validity'] = {'Email': None}\n",
    "\n",
    "    # Uniqueness: Count distinct entries in the Email column\n",
    "    if 'Email' in df.columns:\n",
    "        uniqueness = df['Email'].nunique()\n",
    "        metrics['uniqueness'] = uniqueness\n",
    "    else:\n",
    "        metrics['uniqueness'] = None\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "\n",
    "def calculate_data_quality_score(metrics):\n",
    "    \"\"\"\n",
    "    Calculates an overall data quality score based on the given metrics.\n",
    "    The score is a simple average of completeness, validity, and uniqueness.\n",
    "\n",
    "    Args:\n",
    "        metrics (dict): A dictionary containing the data quality metrics\n",
    "                        as returned by the calculate_data_quality_metrics function.\n",
    "\n",
    "    Returns:\n",
    "        float: The overall data quality score (between 0 and 1).\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    # Average completeness across all columns\n",
    "    if 'completeness' in metrics:\n",
    "        completeness_scores = list(metrics['completeness'].values())\n",
    "        if completeness_scores:  # Check if the list is not empty\n",
    "            avg_completeness = sum(completeness_scores) / len(completeness_scores)\n",
    "            scores.append(avg_completeness)\n",
    "\n",
    "    # Use the validity score for Email\n",
    "    if 'validity' in metrics and 'Email' in metrics['validity'] and metrics['validity']['Email'] is not None:\n",
    "        scores.append(metrics['validity']['Email'])\n",
    "\n",
    "    # Normalize uniqueness to a score between 0 and 1\n",
    "    if 'uniqueness' in metrics:\n",
    "        max_possible_uniqueness = len(df) if 'Name' in df.columns else 0  #added a check.\n",
    "        if max_possible_uniqueness > 0:\n",
    "            uniqueness_score = metrics['uniqueness'] / max_possible_uniqueness\n",
    "            scores.append(uniqueness_score)\n",
    "        elif metrics['uniqueness'] is not None:\n",
    "            scores.append(0) #if max is 0, and uniqueness is 0\n",
    "\n",
    "    if scores:\n",
    "        return sum(scores) / len(scores)\n",
    "    else:\n",
    "        return 0.0  # Return 0 if no metrics are available.\n",
    "\n",
    "\n",
    "\n",
    "def monitor_data_quality(file_path):\n",
    "    \"\"\"\n",
    "    Monitors data quality in real-time (simulated) by repeatedly profiling\n",
    "    data with Great Expectations and using AI (Isolation Forest) to detect anomalies.\n",
    "    Sends alerts if quality drops or anomalies are detected. Also calculates and logs\n",
    "    data quality metrics and overall data quality score.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the CSV file.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        # Simulate data updates\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            # Introduce random changes\n",
    "            if random.random() < 0.2:\n",
    "                if 'age' in df.columns:\n",
    "                    df['age'] = df['age'].apply(lambda x: x + random.randint(-5, 5))\n",
    "                if 'income' in df.columns:\n",
    "                    df['income'] = df['income'].apply(lambda x: x * (1 + random.uniform(-0.1, 0.1)) if pd.notnull(x) else None)\n",
    "                if 'Email' in df.columns:\n",
    "                    df['Email'] = df['Email'].apply(lambda x: f\"invalid_{x}\" if random.random() < 0.1 and isinstance(x, str) else x) # 10% chance of invalidating\n",
    "            df.to_csv(file_path, index=False)\n",
    "            logger.info(f\"Simulated data update at {datetime.datetime.now()}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error reading or updating data: {e}\")\n",
    "            continue  # Go to the next iteration of the loop\n",
    "\n",
    "        # 1. Basic AI Models for Monitoring\n",
    "        #   - Train a simple anomaly detection model using Isolation Forest.\n",
    "        anomaly_data = detect_anomalies(df)\n",
    "\n",
    "        # 2. Use a simple custom function based AI logic for outlier detection.\n",
    "        #    (Example: check if age is outside of expected range)\n",
    "        anomalous_age_data = df[(df['age'] < 0) | (df['age'] > 120)] #0-120\n",
    "        if not anomalous_age_data.empty:\n",
    "            logger.warning(f\"Outliers detected in 'age' column: {anomalous_age_data.to_string()}\")\n",
    "\n",
    "        # Profile data with Great Expectations\n",
    "        validation_status = profile_data_with_great_expectations(file_path)\n",
    "\n",
    "        # 3. Creating a monitoring function that utilizes a pre-trained machine learning model.\n",
    "        #    (This is already happening with the use of detect_anomalies)\n",
    "\n",
    "        # Calculate and log data quality metrics\n",
    "        metrics = calculate_data_quality_metrics(df)\n",
    "        logger.info(f\"Data Quality Metrics: {metrics}\")\n",
    "\n",
    "        # Calculate and log the overall data quality score\n",
    "        overall_score = calculate_data_quality_score(metrics)\n",
    "        logger.info(f\"Overall Data Quality Score: {overall_score:.2f}\")\n",
    "\n",
    "        if not validation_status or not anomaly_data.empty or not anomalous_age_data.empty: #send if GE validation fails or anomalies detected\n",
    "            subject = \"Data Quality and Anomaly Alert\"\n",
    "            body = f\"Data quality check failed at {datetime.datetime.now()}.  Please investigate the data in {file_path}.\"\n",
    "            if not validation_status:\n",
    "                body += \"\\n\\nGreat Expectations validation failed.\"\n",
    "            if not anomaly_data.empty:\n",
    "                body += \"\\n\\nAnomalies detected by Isolation Forest:\\n\"\n",
    "                body += anomaly_data.to_string()\n",
    "            if not anomalous_age_data.empty:\n",
    "                body += \"\\n\\nAnomalies detected in age column:\\n\"\n",
    "                body += anomalous_age_data.to_string()\n",
    "            body += f\"\\n\\nData Quality Metrics: {metrics}\" #append the metrics to email\n",
    "            body += f\"\\n\\nOverall Data Quality Score: {overall_score:.2f}\"\n",
    "            send_email_alert(subject, body)\n",
    "            logger.error(f\"Data quality check failed!\")\n",
    "        else:\n",
    "            logger.info(\"Data quality check successful.\")\n",
    "\n",
    "        time.sleep(60)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Get the file path from the user using st.text_input\n",
    "    default_file_path = \"data.csv\"  # Replace with your default CSV file name\n",
    "    file_path = st.text_input(\"Enter the path to your CSV file:\", default_file_path)\n",
    "\n",
    "    # Create a sample CSV file if it doesn't exist\n",
    "    if not pd.io.common.file_exists(file_path):\n",
    "        df = pd.DataFrame({\n",
    "            'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
    "            'Email': ['alice@example.com', 'bob@example.com', 'charlie@example.com', 'david.com', None],\n",
    "            'Age': [25, 30, 35, 40, 45]\n",
    "        })\n",
    "        df.to_csv(file_path, index=False)\n",
    "        st.info(f\"Created a sample CSV file at {file_path}.  You can replace this with your own data.\")\n",
    "\n",
    "    # Profile data with Pandas-Profiling\n",
    "    st.header(\"Data Profiling with Pandas-Profiling\")\n",
    "    profile_data_with_pandas_profiling(file_path)\n",
    "\n",
    "    # Profile data with Great Expectations\n",
    "    st.header(\"Data Profiling with Great Expectations\")\n",
    "    profile_data_with_great_expectations(file_path)\n",
    "\n",
    "    # Start real-time monitoring in a separate thread\n",
    "    monitoring_thread = threading.Thread(target=monitor_data_quality, args=(file_path,))\n",
    "    monitoring_thread.daemon = True  # Allow the main thread to exit\n",
    "    monitoring_thread.start()\n",
    "\n",
    "    st.subheader(\"Real-time Data Quality Monitoring\")\n",
    "    st.write(\"Data quality is being monitored in the background.  \"\n",
    "             \"Check the console for log messages and email alerts (if any issues are detected).\")\n",
    "\n",
    "    # Keep the main thread alive.\n",
    "    while True:\n",
    "        time.sleep(600)\n",
    "        st.info(\"The main thread is still alive. Monitoring is running in the background...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Creating Expectations for a CSV\n",
    "**Description**: Develop basic data quality expectations using Great Expectations.\n",
    "\n",
    "**Steps**:\n",
    "1. Expectation Suite\n",
    "2. Define Expectations for Completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas_profiling'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas_profiling\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mge\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExpectationSuite, ExpectationConfiguration\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas_profiling'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import great_expectations as ge\n",
    "from great_expectations.core import ExpectationSuite, ExpectationConfiguration\n",
    "import streamlit as st\n",
    "import logging\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "import datetime\n",
    "import time\n",
    "import threading\n",
    "import random\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import numpy as np\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # Set the logging level (e.g., INFO, WARNING, ERROR)\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[logging.StreamHandler()],  # Output to the console\n",
    ")\n",
    "logger = logging.getLogger(__name__)  # Get the logger for this module\n",
    "\n",
    "\n",
    "def profile_data_with_pandas_profiling(file_path):\n",
    "    \"\"\"\n",
    "    Profiles data from a CSV file using Pandas-Profiling.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the CSV file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1. Load the CSV file into a Pandas DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        st.write(f\"Loaded data from: {file_path}\")\n",
    "\n",
    "        # 2. Generate a profile report with default settings\n",
    "        profile = pandas_profiling.ProfileReport(df, title=\"Pandas Profiling Report\")\n",
    "\n",
    "        # Save the report\n",
    "        profile_file_name = file_path.replace(\".csv\", \"_profile.html\")\n",
    "        profile.to_file(profile_file_name)\n",
    "        st.success(f\"Pandas-Profiling report generated and saved to: {profile_file_name}\")\n",
    "\n",
    "        # Display the report in Streamlit\n",
    "        st.header(\"Pandas Profiling Report\")\n",
    "        st.components.v1.html(profile.to_html(), width=800, height=600, scrolling=True)\n",
    "\n",
    "        # 3. Customize the profile report to include correlations and a subset of columns\n",
    "        # Calculate correlations (e.g., Pearson correlation)\n",
    "        profile_with_corr = pandas_profiling.ProfileReport(\n",
    "            df,\n",
    "            title=\"Pandas Profiling Report with Correlations\",\n",
    "            explorative=True,  # Enable more detailed exploration\n",
    "            correlations={\"pearson\": {\"calculate\": True}},  # Calculate Pearson correlation\n",
    "        )\n",
    "\n",
    "        # Save the report with correlations\n",
    "        profile_with_corr_filename = file_path.replace(\".csv\", \"_profile_with_corr.html\")\n",
    "        profile_with_corr.to_file(profile_with_corr_filename)\n",
    "        st.success(f\"Pandas-Profiling report with correlations generated and saved to: {profile_with_corr_filename}\")\n",
    "\n",
    "        # Profile a subset of columns\n",
    "        if 'age' in df.columns and 'income' in df.columns:  # Check if the columns exist\n",
    "            subset_profile = pandas_profiling.ProfileReport(\n",
    "                df[['age', 'income']],  # Profile only 'age' and 'income'\n",
    "                title=\"Pandas Profiling Report - Subset of Columns\",\n",
    "            )\n",
    "            subset_profile_filename = file_path.replace(\".csv\", \"_profile_subset.html\")\n",
    "            subset_profile.to_file(subset_profile_filename)\n",
    "            st.success(f\"Pandas-Profiling report for subset of columns generated and saved to: {subset_profile_filename}\")\n",
    "        else:\n",
    "            st.warning(\"Columns 'age' and 'income' not found in the DataFrame.  Skipping subset profiling.\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        st.error(f\"Error: File not found at {file_path}\")\n",
    "    except Exception as e:\n",
    "        st.error(f\"An error occurred: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "def profile_data_with_great_expectations(file_path):\n",
    "    \"\"\"\n",
    "    Profiles data from a CSV file using Great Expectations.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the CSV file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the CSV file into a Pandas DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        st.write(f\"Loaded data from: {file_path}\")\n",
    "\n",
    "        # Create a Great Expectations context\n",
    "        context = ge.get_context()\n",
    "\n",
    "        # 1. Expectation Suite\n",
    "        # Create an expectation suite (or load an existing one)\n",
    "        expectation_suite_name = \"my_data_suite\"\n",
    "        suite = context.get_expectation_suite(expectation_suite_name)\n",
    "        if suite is None:\n",
    "            suite = context.create_expectation_suite(expectation_suite_name)\n",
    "\n",
    "        # 2. Define Expectations for Completeness\n",
    "        # Define expectations for completeness for all columns\n",
    "        for col in df.columns:\n",
    "            suite.add_expectation(\n",
    "                ge.core.ExpectationConfiguration(\n",
    "                    expectation_type=\"expect_column_values_to_not_be_null\",\n",
    "                    kwargs={\"column\": col, \"mostly\": 1.0},  # Expect 100% completeness\n",
    "                )\n",
    "            )\n",
    "        context.save_expectation_suite(suite, expectation_suite_name=expectation_suite_name)\n",
    "\n",
    "        # Create a BatchRequest\n",
    "        batch_request = ge.datasource.Datasource.create_batch_request(\n",
    "            datasource_name=\"pandas\",  # Use the name 'pandas'\n",
    "            data_asset_name=\"my_data\",  # You can choose any name\n",
    "            pandas_df=df,  # Pass the DataFrame here\n",
    "        )\n",
    "\n",
    "        # 4. Validate data against the expectation suite\n",
    "        validator = context.get_validator(\n",
    "            batch_request=batch_request,\n",
    "            expectation_suite_name=expectation_suite_name,\n",
    "        )\n",
    "        validation_results = validator.validate()\n",
    "\n",
    "        # Print the validation results\n",
    "        st.header(\"Great Expectations Validation Results\")\n",
    "        st.json(validation_results)\n",
    "\n",
    "        # 5. Check if the validation was successful\n",
    "        if validation_results[\"success\"]:\n",
    "            st.success(\"Data validation with Great Expectations was successful!\")\n",
    "            return True  # Return True for success\n",
    "        else:\n",
    "            st.error(\"Data validation with Great Expectations failed!\")\n",
    "            return False  # Return False for failure\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        st.error(f\"Error: File not found at {file_path}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        st.error(f\"An error occurred: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "def send_email_alert(subject, body):\n",
    "    \"\"\"\n",
    "    Sends an email alert.\n",
    "\n",
    "    Args:\n",
    "        subject (str): The subject of the email.\n",
    "        body (str): The body of the email.\n",
    "    \"\"\"\n",
    "    sender_email = \"your_email@example.com\"  # Replace with your email address\n",
    "    receiver_email = \"recipient_email@example.com\"  # Replace with the recipient's email address\n",
    "    smtp_server = \"smtp.example.com\"  # Replace with your SMTP server address\n",
    "    smtp_port = 587  # Replace with your SMTP server port (e.g., 587 for TLS)\n",
    "    smtp_username = \"your_email@example.com\"  # Replace with your email username\n",
    "    smtp_password = \"your_email_password\"  # Replace with your email password or an app password\n",
    "\n",
    "    msg = MIMEText(body)\n",
    "    msg[\"Subject\"] = subject\n",
    "    msg[\"From\"] = sender_email\n",
    "    msg[\"To\"] = receiver_email\n",
    "\n",
    "    try:\n",
    "        server = smtplib.SMTP(smtp_server, smtp_port)\n",
    "        server.starttls()\n",
    "        server.login(smtp_username, smtp_password)\n",
    "        server.sendmail(sender_email, [receiver_email], msg.as_string())\n",
    "        server.quit()\n",
    "        logger.info(\"Email alert sent successfully.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error sending email alert: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "def detect_anomalies(df):\n",
    "    \"\"\"\n",
    "    Detects anomalies in the given DataFrame using Isolation Forest.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the detected anomalies, or an empty DataFrame if no anomalies are found.\n",
    "    \"\"\"\n",
    "    # Handle missing values using imputation (replace NaN with the mean of the column)\n",
    "    df_imputed = df.copy()  # Create a copy to avoid modifying the original DataFrame\n",
    "    for col in df_imputed.columns:\n",
    "        if df_imputed[col].isnull().any():\n",
    "            mean_val = df_imputed[col].mean()\n",
    "            df_imputed[col] = df_imputed[col].fillna(mean_val)\n",
    "\n",
    "    # Initialize and fit the Isolation Forest model\n",
    "    model = IsolationForest(contamination='auto', random_state=42)  # Set random_state for reproducibility\n",
    "    model.fit(df_imputed)\n",
    "\n",
    "    # Predict anomalies (returns 1 for inliers, -1 for outliers)\n",
    "    anomaly_labels = model.predict(df_imputed)\n",
    "\n",
    "    # Get the anomaly data points\n",
    "    anomaly_data = df[anomaly_labels == -1]\n",
    "    return anomaly_data\n",
    "\n",
    "\n",
    "\n",
    "def calculate_data_quality_metrics(df):\n",
    "    \"\"\"\n",
    "    Calculates data quality metrics for the given DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame with columns 'Name', 'Email', and 'Age'.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the calculated metrics:\n",
    "            - completeness (dict): Completeness for each column.\n",
    "            - validity (dict): Validity for the 'Email' column.\n",
    "            - uniqueness (int): Uniqueness of the 'Email' column.\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "\n",
    "    # Completeness: Percentage of non-null values for each column\n",
    "    completeness = {}\n",
    "    for col in df.columns:\n",
    "        completeness[col] = df[col].count() / len(df) if len(df) > 0 else 0\n",
    "    metrics['completeness'] = completeness\n",
    "\n",
    "    # Validity: Percentage of email fields containing '@'\n",
    "    if 'Email' in df.columns:\n",
    "        valid_emails = df['Email'].astype(str).str.contains('@').sum()\n",
    "        validity = (valid_emails / len(df)) if len(df) > 0 else 0\n",
    "        metrics['validity'] = {'Email': validity}\n",
    "    else:\n",
    "        metrics['validity'] = {'Email': None}\n",
    "\n",
    "    # Uniqueness: Count distinct entries in the Email column\n",
    "    if 'Email' in df.columns:\n",
    "        uniqueness = df['Email'].nunique()\n",
    "        metrics['uniqueness'] = uniqueness\n",
    "    else:\n",
    "        metrics['uniqueness'] = None\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "\n",
    "def calculate_data_quality_score(metrics):\n",
    "    \"\"\"\n",
    "    Calculates an overall data quality score based on the given metrics.\n",
    "    The score is a simple average of completeness, validity, and uniqueness.\n",
    "\n",
    "    Args:\n",
    "        metrics (dict): A dictionary containing the data quality metrics\n",
    "                        as returned by the calculate_data_quality_metrics function.\n",
    "\n",
    "    Returns:\n",
    "        float: The overall data quality score (between 0 and 1).\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    # Average completeness across all columns\n",
    "    if 'completeness' in metrics:\n",
    "        completeness_scores = list(metrics['completeness'].values())\n",
    "        if completeness_scores:  # Check if the list is not empty\n",
    "            avg_completeness = sum(completeness_scores) / len(completeness_scores)\n",
    "            scores.append(avg_completeness)\n",
    "\n",
    "    # Use the validity score for Email\n",
    "    if 'validity' in metrics and 'Email' in metrics['validity'] and metrics['validity']['Email'] is not None:\n",
    "        scores.append(metrics['validity']['Email'])\n",
    "\n",
    "    # Normalize uniqueness to a score between 0 and 1\n",
    "    if 'uniqueness' in metrics:\n",
    "        max_possible_uniqueness = len(df) if 'Name' in df.columns else 0  #added a check.\n",
    "        if max_possible_uniqueness > 0:\n",
    "            uniqueness_score = metrics['uniqueness'] / max_possible_uniqueness\n",
    "            scores.append(uniqueness_score)\n",
    "        elif metrics['uniqueness'] is not None:\n",
    "            scores.append(0) #if max is 0, and uniqueness is 0\n",
    "\n",
    "    if scores:\n",
    "        return sum(scores) / len(scores)\n",
    "    else:\n",
    "        return 0.0  # Return 0 if no metrics are available.\n",
    "\n",
    "\n",
    "\n",
    "def monitor_data_quality(file_path):\n",
    "    \"\"\"\n",
    "    Monitors data quality in real-time (simulated) by repeatedly profiling\n",
    "    data with Great Expectations and using AI (Isolation Forest) to detect anomalies.\n",
    "    Sends alerts if quality drops or anomalies are detected. Also calculates and logs\n",
    "    data quality metrics and overall data quality score.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the CSV file.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        # Simulate data updates\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            # Introduce random changes\n",
    "            if random.random() < 0.2:\n",
    "                if 'age' in df.columns:\n",
    "                    df['age'] = df['age'].apply(lambda x: x + random.randint(-5, 5))\n",
    "                if 'income' in df.columns:\n",
    "                    df['income'] = df['income'].apply(lambda x: x * (1 + random.uniform(-0.1, 0.1)) if pd.notnull(x) else None)\n",
    "                if 'Email' in df.columns:\n",
    "                    df['Email'] = df['Email'].apply(lambda x: f\"invalid_{x}\" if random.random() < 0.1 and isinstance(x, str) else x) # 10% chance of invalidating\n",
    "            df.to_csv(file_path, index=False)\n",
    "            logger.info(f\"Simulated data update at {datetime.datetime.now()}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error reading or updating data: {e}\")\n",
    "            continue  # Go to the next iteration of the loop\n",
    "\n",
    "        # 1. Basic AI Models for Monitoring\n",
    "        #   - Train a simple anomaly detection model using Isolation Forest.\n",
    "        anomaly_data = detect_anomalies(df)\n",
    "\n",
    "        # 2. Use a simple custom function based AI logic for outlier detection.\n",
    "        #    (Example: check if age is outside of expected range)\n",
    "        anomalous_age_data = df[(df['age'] < 0) | (df['age'] > 120)] #0-120\n",
    "        if not anomalous_age_data.empty:\n",
    "            logger.warning(f\"Outliers detected in 'age' column: {anomalous_age_data.to_string()}\")\n",
    "\n",
    "        # Profile data with Great Expectations\n",
    "        validation_status = profile_data_with_great_expectations(file_path)\n",
    "\n",
    "        # 3. Creating a monitoring function that utilizes a pre-trained machine learning model.\n",
    "        #    (This is already happening with the use of detect_anomalies)\n",
    "\n",
    "        # Calculate and log data quality metrics\n",
    "        metrics = calculate_data_quality_metrics(df)\n",
    "        logger.info(f\"Data Quality Metrics: {metrics}\")\n",
    "\n",
    "        # Calculate and log the overall data quality score\n",
    "        overall_score = calculate_data_quality_score(metrics)\n",
    "        logger.info(f\"Overall Data Quality Score: {overall_score:.2f}\")\n",
    "\n",
    "        if not validation_status or not anomaly_data.empty or not anomalous_age_data.empty: #send if GE validation fails or anomalies detected\n",
    "            subject = \"Data Quality and Anomaly Alert\"\n",
    "            body = f\"Data quality check failed at {datetime.datetime.now()}.  Please investigate the data in {file_path}.\"\n",
    "            if not validation_status:\n",
    "                body += \"\\n\\nGreat Expectations validation failed.\"\n",
    "            if not anomaly_data.empty:\n",
    "                body += \"\\n\\nAnomalies detected by Isolation Forest:\\n\"\n",
    "                body += anomaly_data.to_string()\n",
    "            if not anomalous_age_data.empty:\n",
    "                body += \"\\n\\nAnomalies detected in age column:\\n\"\n",
    "                body += anomalous_age_data.to_string()\n",
    "            body += f\"\\n\\nData Quality Metrics: {metrics}\" #append the metrics to email\n",
    "            body += f\"\\n\\nOverall Data Quality Score: {overall_score:.2f}\"\n",
    "            send_email_alert(subject, body)\n",
    "            logger.error(f\"Data quality check failed!\")\n",
    "        else:\n",
    "            logger.info(\"Data quality check successful.\")\n",
    "\n",
    "        time.sleep(60)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Get the file path from the user using st.text_input\n",
    "    default_file_path = \"data.csv\"  # Replace with your default CSV file name\n",
    "    file_path = st.text_input(\"Enter the path to your CSV file:\", default_file_path)\n",
    "\n",
    "    # Create a sample CSV file if it doesn't exist\n",
    "    if not pd.io.common.file_exists(file_path):\n",
    "        df = pd.DataFrame({\n",
    "            'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
    "            'Email': ['alice@example.com', 'bob@example.com', 'charlie@example.com', 'david.com', None],\n",
    "            'Age': [25, 30, 35, 40, 45]\n",
    "        })\n",
    "        df.to_csv(file_path, index=False)\n",
    "        st.info(f\"Created a sample CSV file at {file_path}.  You can replace this with your own data.\")\n",
    "\n",
    "    # Profile data with Pandas-Profiling\n",
    "    st.header(\"Data Profiling with Pandas-Profiling\")\n",
    "    profile_data_with_pandas_profiling(file_path)\n",
    "\n",
    "    # Profile data with Great Expectations\n",
    "    st.header(\"Data Profiling with Great Expectations\")\n",
    "    profile_data_with_great_expectations(file_path)\n",
    "\n",
    "    # Start real-time monitoring in a separate thread\n",
    "    monitoring_thread = threading.Thread(target=monitor_data_quality, args=(file_path,))\n",
    "    monitoring_thread.daemon = True  # Allow the main thread to exit\n",
    "    monitoring_thread.start()\n",
    "\n",
    "    st.subheader(\"Real-time Data Quality Monitoring\")\n",
    "    st.write(\"Data quality is being monitored in the background.  \"\n",
    "             \"Check the console for log messages and email alerts (if any issues are detected).\")\n",
    "\n",
    "    # Keep the main thread alive.\n",
    "    while True:\n",
    "        time.sleep(600)\n",
    "        st.info(\"The main thread is still alive. Monitoring is running in the background...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Running and Validating Expectations\n",
    "**Description**: Run the created expectations and generate an output report.\n",
    "\n",
    "**Steps**:\n",
    "1. Validate\n",
    "2. Generate HTML Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas_profiling'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas_profiling\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mge\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExpectationSuite, ExpectationConfiguration\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas_profiling'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import great_expectations as ge\n",
    "from great_expectations.core import ExpectationSuite, ExpectationConfiguration\n",
    "import streamlit as st\n",
    "import logging\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "import datetime\n",
    "import time\n",
    "import threading\n",
    "import random\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import numpy as np\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # Set the logging level (e.g., INFO, WARNING, ERROR)\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[logging.StreamHandler()],  # Output to the console\n",
    ")\n",
    "logger = logging.getLogger(__name__)  # Get the logger for this module\n",
    "\n",
    "\n",
    "def profile_data_with_pandas_profiling(file_path):\n",
    "    \"\"\"\n",
    "    Profiles data from a CSV file using Pandas-Profiling.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the CSV file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1. Load the CSV file into a Pandas DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        st.write(f\"Loaded data from: {file_path}\")\n",
    "\n",
    "        # 2. Generate a profile report with default settings\n",
    "        profile = pandas_profiling.ProfileReport(df, title=\"Pandas Profiling Report\")\n",
    "\n",
    "        # Save the report\n",
    "        profile_file_name = file_path.replace(\".csv\", \"_profile.html\")\n",
    "        profile.to_file(profile_file_name)\n",
    "        st.success(f\"Pandas-Profiling report generated and saved to: {profile_file_name}\")\n",
    "\n",
    "        # Display the report in Streamlit\n",
    "        st.header(\"Pandas Profiling Report\")\n",
    "        st.components.v1.html(profile.to_html(), width=800, height=600, scrolling=True)\n",
    "\n",
    "        # 3. Customize the profile report to include correlations and a subset of columns\n",
    "        # Calculate correlations (e.g., Pearson correlation)\n",
    "        profile_with_corr = pandas_profiling.ProfileReport(\n",
    "            df,\n",
    "            title=\"Pandas Profiling Report with Correlations\",\n",
    "            explorative=True,  # Enable more detailed exploration\n",
    "            correlations={\"pearson\": {\"calculate\": True}},  # Calculate Pearson correlation\n",
    "        )\n",
    "\n",
    "        # Save the report with correlations\n",
    "        profile_with_corr_filename = file_path.replace(\".csv\", \"_profile_with_corr.html\")\n",
    "        profile_with_corr.to_file(profile_with_corr_filename)\n",
    "        st.success(f\"Pandas-Profiling report with correlations generated and saved to: {profile_with_corr_filename}\")\n",
    "\n",
    "        # Profile a subset of columns\n",
    "        if 'age' in df.columns and 'income' in df.columns:  # Check if the columns exist\n",
    "            subset_profile = pandas_profiling.ProfileReport(\n",
    "                df[['age', 'income']],  # Profile only 'age' and 'income'\n",
    "                title=\"Pandas Profiling Report - Subset of Columns\",\n",
    "            )\n",
    "            subset_profile_filename = file_path.replace(\".csv\", \"_profile_subset.html\")\n",
    "            subset_profile.to_file(subset_profile_filename)\n",
    "            st.success(f\"Pandas-Profiling report for subset of columns generated and saved to: {subset_profile_filename}\")\n",
    "        else:\n",
    "            st.warning(\"Columns 'age' and 'income' not found in the DataFrame.  Skipping subset profiling.\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        st.error(f\"Error: File not found at {file_path}\")\n",
    "    except Exception as e:\n",
    "        st.error(f\"An error occurred: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "def profile_data_with_great_expectations(file_path):\n",
    "    \"\"\"\n",
    "    Profiles data from a CSV file using Great Expectations.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the CSV file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the CSV file into a Pandas DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        st.write(f\"Loaded data from: {file_path}\")\n",
    "\n",
    "        # Create a Great Expectations context\n",
    "        context = ge.get_context()\n",
    "\n",
    "        # 1. Expectation Suite\n",
    "        # Create an expectation suite (or load an existing one)\n",
    "        expectation_suite_name = \"my_data_suite\"\n",
    "        suite = context.get_expectation_suite(expectation_suite_name)\n",
    "        if suite is None:\n",
    "            suite = context.create_expectation_suite(expectation_suite_name)\n",
    "\n",
    "        # 2. Define Expectations for Completeness\n",
    "        # Define expectations for completeness for all columns\n",
    "        for col in df.columns:\n",
    "            suite.add_expectation(\n",
    "                ge.core.ExpectationConfiguration(\n",
    "                    expectation_type=\"expect_column_values_to_not_be_null\",\n",
    "                    kwargs={\"column\": col, \"mostly\": 1.0},  # Expect 100% completeness\n",
    "                )\n",
    "            )\n",
    "        context.save_expectation_suite(suite, expectation_suite_name=expectation_suite_name)\n",
    "\n",
    "        # Create a BatchRequest\n",
    "        batch_request = ge.datasource.Datasource.create_batch_request(\n",
    "            datasource_name=\"pandas\",  # Use the name 'pandas'\n",
    "            data_asset_name=\"my_data\",  # You can choose any name\n",
    "            pandas_df=df,  # Pass the DataFrame here\n",
    "        )\n",
    "\n",
    "        # 4. Validate data against the expectation suite\n",
    "        validator = context.get_validator(\n",
    "            batch_request=batch_request,\n",
    "            expectation_suite_name=expectation_suite_name,\n",
    "        )\n",
    "        validation_results = validator.validate()\n",
    "\n",
    "        # Print the validation results\n",
    "        st.header(\"Great Expectations Validation Results\")\n",
    "        st.json(validation_results)\n",
    "\n",
    "        # 5. Check if the validation was successful\n",
    "        if validation_results[\"success\"]:\n",
    "            st.success(\"Data validation with Great Expectations was successful!\")\n",
    "            return True  # Return True for success\n",
    "        else:\n",
    "            st.error(\"Data validation with Great Expectations failed!\")\n",
    "            return False  # Return False for failure\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        st.error(f\"Error: File not found at {file_path}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        st.error(f\"An error occurred: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "def send_email_alert(subject, body):\n",
    "    \"\"\"\n",
    "    Sends an email alert.\n",
    "\n",
    "    Args:\n",
    "        subject (str): The subject of the email.\n",
    "    \"\"\"\n",
    "    sender_email = \"your_email@example.com\"  # Replace with your email address\n",
    "    receiver_email = \"recipient_email@example.com\"  # Replace with the recipient's email address\n",
    "    smtp_server = \"smtp.example.com\"  # Replace with your SMTP server address\n",
    "    smtp_port = 587  # Replace with your SMTP server port (e.g., 587 for TLS)\n",
    "    smtp_username = \"your_email@example.com\"  # Replace with your email username\n",
    "    smtp_password = \"your_email_password\"  # Replace with your email password or an app password\n",
    "\n",
    "    msg = MIMEText(body)\n",
    "    msg[\"Subject\"] = subject\n",
    "    msg[\"From\"] = sender_email\n",
    "    msg[\"To\"] = receiver_email\n",
    "\n",
    "    try:\n",
    "        server = smtplib.SMTP(smtp_server, smtp_port)\n",
    "        server.starttls()\n",
    "        server.login(smtp_username, smtp_password)\n",
    "        server.sendmail(sender_email, [receiver_email], msg.as_string())\n",
    "        server.quit()\n",
    "        logger.info(\"Email alert sent successfully.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error sending email alert: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "def detect_anomalies(df):\n",
    "    \"\"\"\n",
    "    Detects anomalies in the given DataFrame using Isolation Forest.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the detected anomalies, or an empty DataFrame if no anomalies are found.\n",
    "    \"\"\"\n",
    "    # Handle missing values using imputation (replace NaN with the mean of the column)\n",
    "    df_imputed = df.copy()  # Create a copy to avoid modifying the original DataFrame\n",
    "    for col in df_imputed.columns:\n",
    "        if df_imputed[col].isnull().any():\n",
    "            mean_val = df_imputed[col].mean()\n",
    "            df_imputed[col] = df_imputed[col].fillna(mean_val)\n",
    "\n",
    "    # Initialize and fit the Isolation Forest model\n",
    "    model = IsolationForest(contamination='auto', random_state=42)  # Set random_state for reproducibility\n",
    "    model.fit(df_imputed)\n",
    "\n",
    "    # Predict anomalies (returns 1 for inliers, -1 for outliers)\n",
    "    anomaly_labels = model.predict(df_imputed)\n",
    "\n",
    "    # Get the anomaly data points\n",
    "    anomaly_data = df[anomaly_labels == -1]\n",
    "    return anomaly_data\n",
    "\n",
    "\n",
    "\n",
    "def calculate_data_quality_metrics(df):\n",
    "    \"\"\"\n",
    "    Calculates data quality metrics for the given DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame with columns 'Name', 'Email', and 'Age'.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the calculated metrics:\n",
    "            - completeness (dict): Completeness for each column.\n",
    "            - validity (dict): Validity for the 'Email' column.\n",
    "            - uniqueness (int): Uniqueness of the 'Email' column.\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "\n",
    "    # Completeness: Percentage of non-null values for each column\n",
    "    completeness = {}\n",
    "    for col in df.columns:\n",
    "        completeness[col] = df[col].count() / len(df) if len(df) > 0 else 0\n",
    "    metrics['completeness'] = completeness\n",
    "\n",
    "    # Validity: Percentage of email fields containing '@'\n",
    "    if 'Email' in df.columns:\n",
    "        valid_emails = df['Email'].astype(str).str.contains('@').sum()\n",
    "        validity = (valid_emails / len(df)) if len(df) > 0 else 0\n",
    "        metrics['validity'] = {'Email': validity}\n",
    "    else:\n",
    "        metrics['validity'] = {'Email': None}\n",
    "\n",
    "    # Uniqueness: Count distinct entries in the Email column\n",
    "    if 'Email' in df.columns:\n",
    "        uniqueness = df['Email'].nunique()\n",
    "        metrics['uniqueness'] = uniqueness\n",
    "    else:\n",
    "        metrics['uniqueness'] = None\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "\n",
    "def calculate_data_quality_score(metrics):\n",
    "    \"\"\"\n",
    "    Calculates an overall data quality score based on the given metrics.\n",
    "    The score is a simple average of completeness, validity, and uniqueness.\n",
    "\n",
    "    Args:\n",
    "        metrics (dict): A dictionary containing the data quality metrics\n",
    "                        as returned by the calculate_data_quality_metrics function.\n",
    "\n",
    "    Returns:\n",
    "        float: The overall data quality score (between 0 and 1).\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    # Average completeness across all columns\n",
    "    if 'completeness' in metrics:\n",
    "        completeness_scores = list(metrics['completeness'].values())\n",
    "        if completeness_scores:  # Check if the list is not empty\n",
    "            avg_completeness = sum(completeness_scores) / len(completeness_scores)\n",
    "            scores.append(avg_completeness)\n",
    "\n",
    "    # Use the validity score for Email\n",
    "    if 'validity' in metrics and 'Email' in metrics['validity'] and metrics['validity']['Email'] is not None:\n",
    "        scores.append(metrics['validity']['Email'])\n",
    "\n",
    "    # Normalize uniqueness to a score between 0 and 1\n",
    "    if 'uniqueness' in metrics:\n",
    "        max_possible_uniqueness = len(df) if 'Name' in df.columns else 0  #added a check.\n",
    "        if max_possible_uniqueness > 0:\n",
    "            uniqueness_score = metrics['uniqueness'] / max_possible_uniqueness\n",
    "            scores.append(uniqueness_score)\n",
    "        elif metrics['uniqueness'] is not None:\n",
    "            scores.append(0) #if max is 0, and uniqueness is 0\n",
    "\n",
    "    if scores:\n",
    "        return sum(scores) / len(scores)\n",
    "    else:\n",
    "        return 0.0  # Return 0 if no metrics are available.\n",
    "\n",
    "\n",
    "\n",
    "def monitor_data_quality(file_path):\n",
    "    \"\"\"\n",
    "    Monitors data quality in real-time (simulated) by repeatedly profiling\n",
    "    data with Great Expectations and using AI (Isolation Forest) to detect anomalies.\n",
    "    Sends alerts if quality drops or anomalies are detected. Also calculates and logs\n",
    "    data quality metrics and overall data quality score.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the CSV file.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        # Simulate data updates\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            # Introduce random changes\n",
    "            if random.random() < 0.2:\n",
    "                if 'age' in df.columns:\n",
    "                    df['age'] = df['age'].apply(lambda x: x + random.randint(-5, 5))\n",
    "                if 'income' in df.columns:\n",
    "                    df['income'] = df['income'].apply(lambda x: x * (1 + random.uniform(-0.1, 0.1)) if pd.notnull(x) else None)\n",
    "                if 'Email' in df.columns:\n",
    "                    df['Email'] = df['Email'].apply(lambda x: f\"invalid_{x}\" if random.random() < 0.1 and isinstance(x, str) else x) # 10% chance of invalidating\n",
    "            df.to_csv(file_path, index=False)\n",
    "            logger.info(f\"Simulated data update at {datetime.datetime.now()}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error reading or updating data: {e}\")\n",
    "            continue  # Go to the next iteration of the loop\n",
    "\n",
    "        # 1. Basic AI Models for Monitoring\n",
    "        #   - Train a simple anomaly detection model using Isolation Forest.\n",
    "        anomaly_data = detect_anomalies(df)\n",
    "\n",
    "        # 2. Use a simple custom function based AI logic for outlier detection.\n",
    "        #    (Example: check if age is outside of expected range)\n",
    "        anomalous_age_data = df[(df['age'] < 0) | (df['age'] > 120)] #0-120\n",
    "        if not anomalous_age_data.empty:\n",
    "            logger.warning(f\"Outliers detected in 'age' column: {anomalous_age_data.to_string()}\")\n",
    "\n",
    "        # Profile data with Great Expectations\n",
    "        validation_status = profile_data_with_great_expectations(file_path)\n",
    "\n",
    "        # 3. Creating a monitoring function that utilizes a pre-trained machine learning model.\n",
    "        #    (This is already happening with the use of detect_anomalies)\n",
    "\n",
    "        # Calculate and log data quality metrics\n",
    "        metrics = calculate_data_quality_metrics(df)\n",
    "        logger.info(f\"Data Quality Metrics: {metrics}\")\n",
    "\n",
    "        # Calculate and log the overall data quality score\n",
    "        overall_score = calculate_data_quality_score(metrics)\n",
    "        logger.info(f\"Overall Data Quality Score: {overall_score:.2f}\")\n",
    "\n",
    "        if not validation_status or not anomaly_data.empty or not anomalous_age_data.empty: #send if GE validation fails or anomalies detected\n",
    "            subject = \"Data Quality and Anomaly Alert\"\n",
    "            body = f\"Data quality check failed at {datetime.datetime.now()}.  Please investigate the data in {file_path}.\"\n",
    "            if not validation_status:\n",
    "                body += \"\\n\\nGreat Expectations validation failed.\"\n",
    "            if not anomaly_data.empty:\n",
    "                body += \"\\n\\nAnomalies detected by Isolation Forest:\\n\"\n",
    "                body += anomaly_data.to_string()\n",
    "            if not anomalous_age_data.empty:\n",
    "                body += \"\\n\\nAnomalies detected in age column:\\n\"\n",
    "                body += anomalous_age_data.to_string()\n",
    "            body += f\"\\n\\nData Quality Metrics: {metrics}\" #append the metrics to email\n",
    "            body += f\"\\n\\nOverall Data Quality Score: {overall_score:.2f}\"\n",
    "            send_email_alert(subject, body)\n",
    "            logger.error(f\"Data quality check failed!\")\n",
    "        else:\n",
    "            logger.info(\"Data quality check successful.\")\n",
    "\n",
    "        time.sleep(60)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Get the file path from the user using st.text_input\n",
    "    default_file_path = \"data.csv\"  # Replace with your default CSV file name\n",
    "    file_path = st.text_input(\"Enter the path to your CSV file:\", default_file_path)\n",
    "\n",
    "    # Create a sample CSV file if it doesn't exist\n",
    "    if not pd.io.common.file_exists(file_path):\n",
    "        df = pd.DataFrame({\n",
    "            'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
    "            'Email': ['alice@example.com', 'bob@example.com', 'charlie@example.com', 'david.com', None],\n",
    "            'Age': [25, 30, 35, 40, 45]\n",
    "        })\n",
    "        df.to_csv(file_path, index=False)\n",
    "        st.info(f\"Created a sample CSV file at {file_path}.  You can replace this with your own data.\")\n",
    "\n",
    "    # Profile data with Pandas-Profiling\n",
    "    st.header(\"Data Profiling with Pandas-Profiling\")\n",
    "    profile_data_with_pandas_profiling(file_path)\n",
    "\n",
    "    # Profile data with Great Expectations\n",
    "    st.header(\"Data Profiling with Great Expectations\")\n",
    "    profile_data_with_great_expectations(file_path)\n",
    "\n",
    "    # Start real-time monitoring in a separate thread\n",
    "    monitoring_thread = threading.Thread(target=monitor_data_quality, args=(file_path,))\n",
    "    monitoring_thread.daemon = True  # Allow the main thread to exit\n",
    "    monitoring_thread.start()\n",
    "\n",
    "    st.subheader(\"Real-time Data Quality Monitoring\")\n",
    "    st.write(\"Data quality is being monitored in the background.  \"\n",
    "             \"Check the console for log messages and email alerts (if any issues are detected).\")\n",
    "\n",
    "    # Keep the main thread alive.\n",
    "    while True:\n",
    "        time.sleep(600)\n",
    "        st.info(\"The main thread is still alive. Monitoring is running in the background...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Automating Data Quality Score Calculation\n",
    "**Description**: Automate the data quality score via a script that integrates with Great\n",
    "Expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas_profiling'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas_profiling\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mge\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExpectationSuite, ExpectationConfiguration\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas_profiling'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import great_expectations as ge\n",
    "from great_expectations.core import ExpectationSuite, ExpectationConfiguration\n",
    "import streamlit as st\n",
    "import logging\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "import datetime\n",
    "import time\n",
    "import threading\n",
    "import random\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import numpy as np\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # Set the logging level (e.g., INFO, WARNING, ERROR)\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[logging.StreamHandler()],  # Output to the console\n",
    ")\n",
    "logger = logging.getLogger(__name__)  # Get the logger for this module\n",
    "\n",
    "\n",
    "def profile_data_with_pandas_profiling(file_path):\n",
    "    \"\"\"\n",
    "    Profiles data from a CSV file using Pandas-Profiling.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the CSV file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1. Load the CSV file into a Pandas DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        st.write(f\"Loaded data from: {file_path}\")\n",
    "\n",
    "        # 2. Generate a profile report with default settings\n",
    "        profile = pandas_profiling.ProfileReport(df, title=\"Pandas Profiling Report\")\n",
    "\n",
    "        # Save the report\n",
    "        profile_file_name = file_path.replace(\".csv\", \"_profile.html\")\n",
    "        profile.to_file(profile_file_name)\n",
    "        st.success(f\"Pandas-Profiling report generated and saved to: {profile_file_name}\")\n",
    "\n",
    "        # Display the report in Streamlit\n",
    "        st.header(\"Pandas Profiling Report\")\n",
    "        st.components.v1.html(profile.to_html(), width=800, height=600, scrolling=True)\n",
    "\n",
    "        # 3. Customize the profile report to include correlations and a subset of columns\n",
    "        # Calculate correlations (e.g., Pearson correlation)\n",
    "        profile_with_corr = pandas_profiling.ProfileReport(\n",
    "            df,\n",
    "            title=\"Pandas Profiling Report with Correlations\",\n",
    "            explorative=True,  # Enable more detailed exploration\n",
    "            correlations={\"pearson\": {\"calculate\": True}},  # Calculate Pearson correlation\n",
    "        )\n",
    "\n",
    "        # Save the report with correlations\n",
    "        profile_with_corr_filename = file_path.replace(\".csv\", \"_profile_with_corr.html\")\n",
    "        profile_with_corr.to_file(profile_with_corr_filename)\n",
    "        st.success(f\"Pandas-Profiling report with correlations generated and saved to: {profile_with_corr_filename}\")\n",
    "\n",
    "        # Profile a subset of columns\n",
    "        if 'age' in df.columns and 'income' in df.columns:  # Check if the columns exist\n",
    "            subset_profile = pandas_profiling.ProfileReport(\n",
    "                df[['age', 'income']],  # Profile only 'age' and 'income'\n",
    "                title=\"Pandas Profiling Report - Subset of Columns\",\n",
    "            )\n",
    "            subset_profile_filename = file_path.replace(\".csv\", \"_profile_subset.html\")\n",
    "            subset_profile.to_file(subset_profile_filename)\n",
    "            st.success(f\"Pandas-Profiling report for subset of columns generated and saved to: {subset_profile_filename}\")\n",
    "        else:\n",
    "            st.warning(\"Columns 'age' and 'income' not found in the DataFrame.  Skipping subset profiling.\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        st.error(f\"Error: File not found at {file_path}\")\n",
    "    except Exception as e:\n",
    "        st.error(f\"An error occurred: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "def profile_data_with_great_expectations(file_path):\n",
    "    \"\"\"\n",
    "    Profiles data from a CSV file using Great Expectations.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the CSV file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the CSV file into a Pandas DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        st.write(f\"Loaded data from: {file_path}\")\n",
    "\n",
    "        # Create a Great Expectations context\n",
    "        context = ge.get_context()\n",
    "\n",
    "        # 1. Expectation Suite\n",
    "        # Create an expectation suite (or load an existing one)\n",
    "        expectation_suite_name = \"my_data_suite\"\n",
    "        suite = context.get_expectation_suite(expectation_suite_name)\n",
    "        if suite is None:\n",
    "            suite = context.create_expectation_suite(expectation_suite_name)\n",
    "\n",
    "        # 2. Define Expectations for Completeness\n",
    "        # Define expectations for completeness for all columns\n",
    "        for col in df.columns:\n",
    "            suite.add_expectation(\n",
    "                ge.core.ExpectationConfiguration(\n",
    "                    expectation_type=\"expect_column_values_to_not_be_null\",\n",
    "                    kwargs={\"column\": col, \"mostly\": 1.0},  # Expect 100% completeness\n",
    "                )\n",
    "            )\n",
    "        context.save_expectation_suite(suite, expectation_suite_name=expectation_suite_name)\n",
    "\n",
    "        # Create a BatchRequest\n",
    "        batch_request = ge.datasource.Datasource.create_batch_request(\n",
    "            datasource_name=\"pandas\",  # Use the name 'pandas'\n",
    "            data_asset_name=\"my_data\",  # You can choose any name\n",
    "            pandas_df=df,  # Pass the DataFrame here\n",
    "        )\n",
    "\n",
    "        # 4. Validate data against the expectation suite\n",
    "        validator = context.get_validator(\n",
    "            batch_request=batch_request,\n",
    "            expectation_suite_name=expectation_suite_name,\n",
    "        )\n",
    "        validation_results = validator.validate()\n",
    "\n",
    "        # Print the validation results\n",
    "        st.header(\"Great Expectations Validation Results\")\n",
    "        st.json(validation_results)\n",
    "\n",
    "        # 5. Check if the validation was successful\n",
    "        if validation_results[\"success\"]:\n",
    "            st.success(\"Data validation with Great Expectations was successful!\")\n",
    "            return True  # Return True for success\n",
    "        else:\n",
    "            st.error(\"Data validation with Great Expectations failed!\")\n",
    "            return False  # Return False for failure\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        st.error(f\"Error: File not found at {file_path}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        st.error(f\"An error occurred: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "def send_email_alert(subject, body):\n",
    "    \"\"\"\n",
    "    Sends an email alert.\n",
    "\n",
    "    Args:\n",
    "        subject (str): The subject of the email.\n",
    "    \"\"\"\n",
    "    sender_email = \"your_email@example.com\"  # Replace with your email address\n",
    "    receiver_email = \"recipient_email@example.com\"  # Replace with the recipient's email address\n",
    "    smtp_server = \"smtp.example.com\"  # Replace with your SMTP server address\n",
    "    smtp_port = 587  # Replace with your SMTP server port (e.g., 587 for TLS)\n",
    "    smtp_username = \"your_email@example.com\"  # Replace with your email username\n",
    "    smtp_password = \"your_email_password\"  # Replace with your email password or an app password\n",
    "\n",
    "    msg = MIMEText(body)\n",
    "    msg[\"Subject\"] = subject\n",
    "    msg[\"From\"] = sender_email\n",
    "    msg[\"To\"] = receiver_email\n",
    "\n",
    "    try:\n",
    "        server = smtplib.SMTP(smtp_server, smtp_port)\n",
    "        server.starttls()\n",
    "        server.login(smtp_username, smtp_password)\n",
    "        server.sendmail(sender_email, [receiver_email], msg.as_string())\n",
    "        server.quit()\n",
    "        logger.info(\"Email alert sent successfully.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error sending email alert: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "def detect_anomalies(df):\n",
    "    \"\"\"\n",
    "    Detects anomalies in the given DataFrame using Isolation Forest.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the detected anomalies, or an empty DataFrame if no anomalies are found.\n",
    "    \"\"\"\n",
    "    # Handle missing values using imputation (replace NaN with the mean of the column)\n",
    "    df_imputed = df.copy()  # Create a copy to avoid modifying the original DataFrame\n",
    "    for col in df_imputed.columns:\n",
    "        if df_imputed[col].isnull().any():\n",
    "            mean_val = df_imputed[col].mean()\n",
    "            df_imputed[col] = df_imputed[col].fillna(mean_val)\n",
    "\n",
    "    # Initialize and fit the Isolation Forest model\n",
    "    model = IsolationForest(contamination='auto', random_state=42)  # Set random_state for reproducibility\n",
    "    model.fit(df_imputed)\n",
    "\n",
    "    # Predict anomalies (returns 1 for inliers, -1 for outliers)\n",
    "    anomaly_labels = model.predict(df_imputed)\n",
    "\n",
    "    # Get the anomaly data points\n",
    "    anomaly_data = df[anomaly_labels == -1]\n",
    "    return anomaly_data\n",
    "\n",
    "\n",
    "\n",
    "def calculate_data_quality_metrics(df):\n",
    "    \"\"\"\n",
    "    Calculates data quality metrics for the given DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame with columns 'Name', 'Email', and 'Age'.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the calculated metrics:\n",
    "            - completeness (dict): Completeness for each column.\n",
    "            - validity (dict): Validity for the 'Email' column.\n",
    "            - uniqueness (int): Uniqueness of the 'Email' column.\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "\n",
    "    # Completeness: Percentage of non-null values for each column\n",
    "    completeness = {}\n",
    "    for col in df.columns:\n",
    "        completeness[col] = df[col].count() / len(df) if len(df) > 0 else 0\n",
    "    metrics['completeness'] = completeness\n",
    "\n",
    "    # Validity: Percentage of email fields containing '@'\n",
    "    if 'Email' in df.columns:\n",
    "        valid_emails = df['Email'].astype(str).str.contains('@').sum()\n",
    "        validity = (valid_emails / len(df)) if len(df) > 0 else 0\n",
    "        metrics['validity'] = {'Email': validity}\n",
    "    else:\n",
    "        metrics['validity'] = {'Email': None}\n",
    "\n",
    "    # Uniqueness: Count distinct entries in the Email column\n",
    "    if 'Email' in df.columns:\n",
    "        uniqueness = df['Email'].nunique()\n",
    "        metrics['uniqueness'] = uniqueness\n",
    "    else:\n",
    "        metrics['uniqueness'] = None\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "\n",
    "def calculate_data_quality_score(metrics, df):\n",
    "    \"\"\"\n",
    "    Calculates an overall data quality score based on the given metrics.\n",
    "    The score is a simple average of completeness, validity, and uniqueness.\n",
    "\n",
    "    Args:\n",
    "        metrics (dict): A dictionary containing the data quality metrics\n",
    "                        as returned by the calculate_data_quality_metrics function.\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        float: The overall data quality score (between 0 and 1).\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    # Average completeness across all columns\n",
    "    if 'completeness' in metrics:\n",
    "        completeness_scores = list(metrics['completeness'].values())\n",
    "        if completeness_scores:  # Check if the list is not empty\n",
    "            avg_completeness = sum(completeness_scores) / len(completeness_scores)\n",
    "            scores.append(avg_completeness)\n",
    "\n",
    "    # Use the validity score for Email\n",
    "    if 'validity' in metrics and 'Email' in metrics['validity'] and metrics['validity']['Email'] is not None:\n",
    "        scores.append(metrics['validity']['Email'])\n",
    "\n",
    "    # Normalize uniqueness to a score between 0 and 1\n",
    "    if 'uniqueness' in metrics:\n",
    "        max_possible_uniqueness = len(df) if 'Name' in df.columns else 0  #added a check.\n",
    "        if max_possible_uniqueness > 0:\n",
    "            uniqueness_score = metrics['uniqueness'] / max_possible_uniqueness\n",
    "            scores.append(uniqueness_score)\n",
    "        elif metrics['uniqueness'] is not None:\n",
    "            scores.append(0) #if max is 0, and uniqueness is 0\n",
    "\n",
    "    if scores:\n",
    "        return sum(scores) / len(scores)\n",
    "    else:\n",
    "        return 0.0  # Return 0 if no metrics are available.\n",
    "\n",
    "\n",
    "\n",
    "def monitor_data_quality(file_path):\n",
    "    \"\"\"\n",
    "    Monitors data quality in real-time (simulated) by repeatedly profiling\n",
    "    data with Great Expectations and using AI (Isolation Forest) to detect anomalies.\n",
    "    Sends alerts if quality drops or anomalies are detected. Also calculates and logs\n",
    "    data quality metrics and overall data quality score.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the CSV file.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        # Simulate data updates\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            # Introduce random changes\n",
    "            if random.random() < 0.2:\n",
    "                if 'age' in df.columns:\n",
    "                    df['age'] = df['age'].apply(lambda x: x + random.randint(-5, 5))\n",
    "                if 'income' in df.columns:\n",
    "                    df['income'] = df['income'].apply(lambda x: x * (1 + random.uniform(-0.1, 0.1)) if pd.notnull(x) else None)\n",
    "                if 'Email' in df.columns:\n",
    "                    df['Email'] = df['Email'].apply(lambda x: f\"invalid_{x}\" if random.random() < 0.1 and isinstance(x, str) else x) # 10% chance of invalidating\n",
    "            df.to_csv(file_path, index=False)\n",
    "            logger.info(f\"Simulated data update at {datetime.datetime.now()}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error reading or updating data: {e}\")\n",
    "            continue  # Go to the next iteration of the loop\n",
    "\n",
    "        # 1. Basic AI Models for Monitoring\n",
    "        #   - Train a simple anomaly detection model using Isolation Forest.\n",
    "        anomaly_data = detect_anomalies(df)\n",
    "\n",
    "        # 2. Use a simple custom function based AI logic for outlier detection.\n",
    "        #    (Example: check if age is outside of expected range)\n",
    "        anomalous_age_data = df[(df['age'] < 0) | (df['age'] > 120)] #0-120\n",
    "        if not anomalous_age_data.empty:\n",
    "            logger.warning(f\"Outliers detected in 'age' column: {anomalous_age_data.to_string()}\")\n",
    "\n",
    "        # Profile data with Great Expectations\n",
    "        validation_status = profile_data_with_great_expectations(file_path)\n",
    "\n",
    "        # 3. Creating a monitoring function that utilizes a pre-trained machine learning model.\n",
    "        #    (This is already happening with the use of detect_anomalies)\n",
    "\n",
    "        # Calculate and log data quality metrics\n",
    "        metrics = calculate_data_quality_metrics(df)\n",
    "        logger.info(f\"Data Quality Metrics: {metrics}\")\n",
    "\n",
    "        # Calculate and log the overall data quality score\n",
    "        overall_score = calculate_data_quality_score(metrics, df)\n",
    "        logger.info(f\"Overall Data Quality Score: {overall_score:.2f}\")\n",
    "\n",
    "        if not validation_status or not anomaly_data.empty or not anomalous_age_data.empty: #send if GE validation fails or anomalies detected\n",
    "            subject = \"Data Quality and Anomaly Alert\"\n",
    "            body = f\"Data quality check failed at {datetime.datetime.now()}.  Please investigate the data in {file_path}.\"\n",
    "            if not validation_status:\n",
    "                body += \"\\n\\nGreat Expectations validation failed.\"\n",
    "            if not anomaly_data.empty:\n",
    "                body += \"\\n\\nAnomalies detected by Isolation Forest:\\n\"\n",
    "                body += anomaly_data.to_string()\n",
    "            if not anomalous_age_data.empty:\n",
    "                body += \"\\n\\nAnomalies detected in age column:\\n\"\n",
    "                body += anomalous_age_data.to_string()\n",
    "            body += f\"\\n\\nData Quality Metrics: {metrics}\" #append the metrics to email\n",
    "            body += f\"\\n\\nOverall Data Quality Score: {overall_score:.2f}\"\n",
    "            send_email_alert(subject, body)\n",
    "            logger.error(f\"Data quality check failed!\")\n",
    "        else:\n",
    "            logger.info(\"Data quality check successful.\")\n",
    "\n",
    "        time.sleep(60)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Get the file path from the user using st.text_input\n",
    "    default_file_path = \"data.csv\"  # Replace with your default CSV file name\n",
    "    file_path = st.text_input(\"Enter the path to your CSV file:\", default_file_path)\n",
    "\n",
    "    # Create a sample CSV file if it doesn't exist\n",
    "    if not pd.io.common.file_exists(file_path):\n",
    "        df = pd.DataFrame({\n",
    "            'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
    "            'Email': ['alice@example.com', 'bob@example.com', 'charlie@example.com', 'david.com', None],\n",
    "            'Age': [25, 30, 35, 40, 45]\n",
    "        })\n",
    "        df.to_csv(file_path, index=False)\n",
    "        st.info(f\"Created a sample CSV file at {file_path}.  You can replace this with your own data.\")\n",
    "\n",
    "    # Profile data with Pandas-Profiling\n",
    "    st.header(\"Data Profiling with Pandas-Profiling\")\n",
    "    profile_data_with_pandas_profiling(file_path)\n",
    "\n",
    "    # Profile data with Great Expectations\n",
    "    st.header(\"Data Profiling with Great Expectations\")\n",
    "    profile_data_with_great_expectations(file_path)\n",
    "\n",
    "    # Start real-time monitoring in a separate thread\n",
    "    monitoring_thread = threading.Thread(target=monitor_data_quality, args=(file_path,))\n",
    "    monitoring_thread.daemon = True  # Allow the main thread to exit\n",
    "    monitoring_thread.start()\n",
    "\n",
    "    st.subheader(\"Real-time Data Quality Monitoring\")\n",
    "    st.write(\"Data quality is being monitored in the background.  \"\n",
    "             \"Check the console for log messages and email alerts (if any issues are detected).\")\n",
    "\n",
    "    # Keep the main thread alive.\n",
    "    while True:\n",
    "        time.sleep(600)\n",
    "        st.info(\"The main thread is still alive. Monitoring is running in the background...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6: Leveraging Data Quality Metrics for Automated Data Cleaning\n",
    "**Description**: Implement a system where if data quality metrics fall below a threshold,\n",
    "automated data cleaning scripts are triggered.\n",
    "\n",
    "**Steps**:\n",
    "1. Define Cleaning Logic\n",
    "2. Integrate with Great Expectations:\n",
    "    - Use an action within the Great Expectations action list that only triggers if quality score is below a threshold, automating the cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas_profiling'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas_profiling\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mge\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExpectationSuite, ExpectationConfiguration\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas_profiling'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import great_expectations as ge\n",
    "from great_expectations.core import ExpectationSuite, ExpectationConfiguration\n",
    "import streamlit as st\n",
    "import logging\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "import datetime\n",
    "import time\n",
    "import threading\n",
    "import random\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import numpy as np\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,  # Set the logging level (e.g., INFO, WARNING, ERROR)\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[logging.StreamHandler()],  # Output to the console\n",
    ")\n",
    "logger = logging.getLogger(__name__)  # Get the logger for this module\n",
    "\n",
    "\n",
    "def profile_data_with_pandas_profiling(file_path):\n",
    "    \"\"\"\n",
    "    Profiles data from a CSV file using Pandas-Profiling.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the CSV file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1. Load the CSV file into a Pandas DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        st.write(f\"Loaded data from: {file_path}\")\n",
    "\n",
    "        # 2. Generate a profile report with default settings\n",
    "        profile = pandas_profiling.ProfileReport(df, title=\"Pandas Profiling Report\")\n",
    "\n",
    "        # Save the report\n",
    "        profile_file_name = file_path.replace(\".csv\", \"_profile.html\")\n",
    "        profile.to_file(profile_file_name)\n",
    "        st.success(f\"Pandas-Profiling report generated and saved to: {profile_file_name}\")\n",
    "\n",
    "        # Display the report in Streamlit\n",
    "        st.header(\"Pandas Profiling Report\")\n",
    "        st.components.v1.html(profile.to_html(), width=800, height=600, scrolling=True)\n",
    "\n",
    "        # 3. Customize the profile report to include correlations and a subset of columns\n",
    "        # Calculate correlations (e.g., Pearson correlation)\n",
    "        profile_with_corr = pandas_profiling.ProfileReport(\n",
    "            df,\n",
    "            title=\"Pandas Profiling Report with Correlations\",\n",
    "            explorative=True,  # Enable more detailed exploration\n",
    "            correlations={\"pearson\": {\"calculate\": True}},  # Calculate Pearson correlation\n",
    "        )\n",
    "\n",
    "        # Save the report with correlations\n",
    "        profile_with_corr_filename = file_path.replace(\".csv\", \"_profile_with_corr.html\")\n",
    "        profile_with_corr.to_file(profile_with_corr_filename)\n",
    "        st.success(f\"Pandas-Profiling report with correlations generated and saved to: {profile_with_corr_filename}\")\n",
    "\n",
    "        # Profile a subset of columns\n",
    "        if 'age' in df.columns and 'income' in df.columns:  # Check if the columns exist\n",
    "            subset_profile = pandas_profiling.ProfileReport(\n",
    "                df[['age', 'income']],  # Profile only 'age' and 'income'\n",
    "                title=\"Pandas Profiling Report - Subset of Columns\",\n",
    "            )\n",
    "            subset_profile_filename = file_path.replace(\".csv\", \"_profile_subset.html\")\n",
    "            subset_profile.to_file(subset_profile_filename)\n",
    "            st.success(f\"Pandas-Profiling report for subset of columns generated and saved to: {subset_profile_filename}\")\n",
    "        else:\n",
    "            st.warning(\"Columns 'age' and 'income' not found in the DataFrame.  Skipping subset profiling.\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        st.error(f\"Error: File not found at {file_path}\")\n",
    "    except Exception as e:\n",
    "        st.error(f\"An error occurred: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "def profile_data_with_great_expectations(file_path):\n",
    "    \"\"\"\n",
    "    Profiles data from a CSV file using Great Expectations.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the CSV file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the CSV file into a Pandas DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        st.write(f\"Loaded data from: {file_path}\")\n",
    "\n",
    "        # Create a Great Expectations context\n",
    "        context = ge.get_context()\n",
    "\n",
    "        # 1. Expectation Suite\n",
    "        # Create an expectation suite (or load an existing one)\n",
    "        expectation_suite_name = \"my_data_suite\"\n",
    "        suite = context.get_expectation_suite(expectation_suite_name)\n",
    "        if suite is None:\n",
    "            suite = context.create_expectation_suite(expectation_suite_name)\n",
    "\n",
    "        # 2. Define Expectations for Completeness\n",
    "        # Define expectations for completeness for all columns\n",
    "        for col in df.columns:\n",
    "            suite.add_expectation(\n",
    "                ge.core.ExpectationConfiguration(\n",
    "                    expectation_type=\"expect_column_values_to_not_be_null\",\n",
    "                    kwargs={\"column\": col, \"mostly\": 1.0},  # Expect 100% completeness\n",
    "                )\n",
    "            )\n",
    "        context.save_expectation_suite(suite, expectation_suite_name=expectation_suite_name)\n",
    "\n",
    "        # Create a BatchRequest\n",
    "        batch_request = ge.datasource.Datasource.create_batch_request(\n",
    "            datasource_name=\"pandas\",  # Use the name 'pandas'\n",
    "            data_asset_name=\"my_data\",  # You can choose any name\n",
    "            pandas_df=df,  # Pass the DataFrame here\n",
    "        )\n",
    "\n",
    "        # 4. Validate data against the expectation suite\n",
    "        validator = context.get_validator(\n",
    "            batch_request=batch_request,\n",
    "            expectation_suite_name=expectation_suite_name,\n",
    "        )\n",
    "        validation_results = validator.validate()\n",
    "\n",
    "        # Print the validation results\n",
    "        st.header(\"Great Expectations Validation Results\")\n",
    "        st.json(validation_results)\n",
    "\n",
    "        # 5. Check if the validation was successful\n",
    "        if validation_results[\"success\"]:\n",
    "            st.success(\"Data validation with Great Expectations was successful!\")\n",
    "            return True  # Return True for success\n",
    "        else:\n",
    "            st.error(\"Data validation with Great Expectations failed!\")\n",
    "            return False  # Return False for failure\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        st.error(f\"Error: File not found at {file_path}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        st.error(f\"An error occurred: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "def send_email_alert(subject, body):\n",
    "    \"\"\"\n",
    "    Sends an email alert.\n",
    "\n",
    "    Args:\n",
    "        subject (str): The subject of the email.\n",
    "    \"\"\"\n",
    "    sender_email = \"your_email@example.com\"  # Replace with your email address\n",
    "    receiver_email = \"recipient_email@example.com\"  # Replace with the recipient's email address\n",
    "    smtp_server = \"smtp.example.com\"  # Replace with your SMTP server address\n",
    "    smtp_port = 587  # Replace with your SMTP server port (e.g., 587 for TLS)\n",
    "    smtp_username = \"your_email@example.com\"  # Replace with your email username\n",
    "    smtp_password = \"your_email_password\"  # Replace with your email password or an app password\n",
    "\n",
    "    msg = MIMEText(body)\n",
    "    msg[\"Subject\"] = subject\n",
    "    msg[\"From\"] = sender_email\n",
    "    msg[\"To\"] = receiver_email\n",
    "\n",
    "    try:\n",
    "        server = smtplib.SMTP(smtp_server, smtp_port)\n",
    "        server.starttls()\n",
    "        server.login(smtp_username, smtp_password)\n",
    "        server.sendmail(sender_email, [receiver_email], msg.as_string())\n",
    "        server.quit()\n",
    "        logger.info(\"Email alert sent successfully.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error sending email alert: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "def detect_anomalies(df):\n",
    "    \"\"\"\n",
    "    Detects anomalies in the given DataFrame using Isolation Forest.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the detected anomalies, or an empty DataFrame if no anomalies are found.\n",
    "    \"\"\"\n",
    "    # Handle missing values using imputation (replace NaN with the mean of the column)\n",
    "    df_imputed = df.copy()  # Create a copy to avoid modifying the original DataFrame\n",
    "    for col in df_imputed.columns:\n",
    "        if df_imputed[col].isnull().any():\n",
    "            mean_val = df_imputed[col].mean()\n",
    "            df_imputed[col] = df_imputed[col].fillna(mean_val)\n",
    "\n",
    "    # Initialize and fit the Isolation Forest model\n",
    "    model = IsolationForest(contamination='auto', random_state=42)  # Set random_state for reproducibility\n",
    "    model.fit(df_imputed)\n",
    "\n",
    "    # Predict anomalies (returns 1 for inliers, -1 for outliers)\n",
    "    anomaly_labels = model.predict(df_imputed)\n",
    "\n",
    "    # Get the anomaly data points\n",
    "    anomaly_data = df[anomaly_labels == -1]\n",
    "    return anomaly_data\n",
    "\n",
    "\n",
    "\n",
    "def calculate_data_quality_metrics(df):\n",
    "    \"\"\"\n",
    "    Calculates data quality metrics for the given DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame with columns 'Name', 'Email', and 'Age'.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the calculated metrics:\n",
    "            - completeness (dict): Completeness for each column.\n",
    "            - validity (dict): Validity for the 'Email' column.\n",
    "            - uniqueness (int): Uniqueness of the 'Email' column.\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "\n",
    "    # Completeness: Percentage of non-null values for each column\n",
    "    completeness = {}\n",
    "    for col in df.columns:\n",
    "        completeness[col] = df[col].count() / len(df) if len(df) > 0 else 0\n",
    "    metrics['completeness'] = completeness\n",
    "\n",
    "    # Validity: Percentage of email fields containing '@'\n",
    "    if 'Email' in df.columns:\n",
    "        valid_emails = df['Email'].astype(str).str.contains('@').sum()\n",
    "        validity = (valid_emails / len(df)) if len(df) > 0 else 0\n",
    "        metrics['validity'] = {'Email': validity}\n",
    "    else:\n",
    "        metrics['validity'] = {'Email': None}\n",
    "\n",
    "    # Uniqueness: Count distinct entries in the Email column\n",
    "    if 'Email' in df.columns:\n",
    "        uniqueness = df['Email'].nunique()\n",
    "        metrics['uniqueness'] = uniqueness\n",
    "    else:\n",
    "        metrics['uniqueness'] = None\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "\n",
    "def calculate_data_quality_score(metrics, df):\n",
    "    \"\"\"\n",
    "    Calculates an overall data quality score based on the given metrics.\n",
    "    The score is a simple average of completeness, validity, and uniqueness.\n",
    "\n",
    "    Args:\n",
    "        metrics (dict): A dictionary containing the data quality metrics\n",
    "                        as returned by the calculate_data_quality_metrics function.\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        float: The overall data quality score (between 0 and 1).\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    # Average completeness across all columns\n",
    "    if 'completeness' in metrics:\n",
    "        completeness_scores = list(metrics['completeness'].values())\n",
    "        if completeness_scores:  # Check if the list is not empty\n",
    "            avg_completeness = sum(completeness_scores) / len(completeness_scores)\n",
    "            scores.append(avg_completeness)\n",
    "\n",
    "    # Use the validity score for Email\n",
    "    if 'validity' in metrics and 'Email' in metrics['validity'] and metrics['validity']['Email'] is not None:\n",
    "        scores.append(metrics['validity']['Email'])\n",
    "\n",
    "    # Normalize uniqueness to a score between 0 and 1\n",
    "    if 'uniqueness' in metrics:\n",
    "        max_possible_uniqueness = len(df) if 'Name' in df.columns else 0  #added a check.\n",
    "        if max_possible_uniqueness > 0:\n",
    "            uniqueness_score = metrics['uniqueness'] / max_possible_uniqueness\n",
    "            scores.append(uniqueness_score)\n",
    "        elif metrics['uniqueness'] is not None:\n",
    "            scores.append(0) #if max is 0, and uniqueness is 0\n",
    "\n",
    "    if scores:\n",
    "        return sum(scores) / len(scores)\n",
    "    else:\n",
    "        return 0.0  # Return 0 if no metrics are available.\n",
    "\n",
    "\n",
    "\n",
    "def clean_data(df):\n",
    "    \"\"\"\n",
    "    Cleans the data in the DataFrame.  This is a placeholder for your actual cleaning logic.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame to clean.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The cleaned DataFrame.\n",
    "    \"\"\"\n",
    "    # 1. Define Cleaning Logic\n",
    "    # Example cleaning:\n",
    "    #  - Remove rows with missing 'Name' or 'Email'\n",
    "    #  - Fill missing ages with the median age\n",
    "    df_cleaned = df.dropna(subset=['Name', 'Email'])\n",
    "    if 'Age' in df_cleaned.columns:\n",
    "        median_age = df_cleaned['Age'].median()\n",
    "        df_cleaned['Age'] = df_cleaned['Age'].fillna(median_age)\n",
    "    logger.info(\"Data cleaning performed.\")\n",
    "    return df_cleaned\n",
    "\n",
    "\n",
    "\n",
    "def monitor_data_quality(file_path):\n",
    "    \"\"\"\n",
    "    Monitors data quality in real-time (simulated) by repeatedly profiling\n",
    "    data with Great Expectations and using AI (Isolation Forest) to detect anomalies.\n",
    "    Sends alerts if quality drops or anomalies are detected. Also calculates and logs\n",
    "    data quality metrics and overall data quality score.  If the data quality score\n",
    "    falls below a threshold, automated data cleaning is triggered.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the CSV file.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        # Simulate data updates\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            # Introduce random changes\n",
    "            if random.random() < 0.2:\n",
    "                if 'age' in df.columns:\n",
    "                    df['age'] = df['age'].apply(lambda x: x + random.randint(-5, 5))\n",
    "                if 'income' in df.columns:\n",
    "                    df['income'] = df['income'].apply(lambda x: x * (1 + random.uniform(-0.1, 0.1)) if pd.notnull(x) else None)\n",
    "                if 'Email' in df.columns:\n",
    "                    df['Email'] = df['Email'].apply(lambda x: f\"invalid_{x}\" if random.random() < 0.1 and isinstance(x, str) else x) # 10% chance of invalidating\n",
    "            df.to_csv(file_path, index=False)\n",
    "            logger.info(f\"Simulated data update at {datetime.datetime.now()}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error reading or updating data: {e}\")\n",
    "            continue  # Go to the next iteration of the loop\n",
    "\n",
    "        # 1. Basic AI Models for Monitoring\n",
    "        #   - Train a simple anomaly detection model using Isolation Forest.\n",
    "        anomaly_data = detect_anomalies(df)\n",
    "\n",
    "        # 2. Use a simple custom function based AI logic for outlier detection.\n",
    "        #    (Example: check if age is outside of expected range)\n",
    "        anomalous_age_data = df[(df['age'] < 0) | (df['age'] > 120)] #0-120\n",
    "        if not anomalous_age_data.empty:\n",
    "            logger.warning(f\"Outliers detected in 'age' column: {anomalous_age_data.to_string()}\")\n",
    "\n",
    "        # Profile data with Great Expectations\n",
    "        validation_status = profile_data_with_great_expectations(file_path)\n",
    "\n",
    "        # 3. Creating a monitoring function that utilizes a pre-trained machine learning model.\n",
    "        #    (This is already happening with the use of detect_anomalies)\n",
    "\n",
    "        # Calculate and log data quality metrics\n",
    "        metrics = calculate_data_quality_metrics(df)\n",
    "        logger.info(f\"Data Quality Metrics: {metrics}\")\n",
    "\n",
    "        # Calculate and log the overall data quality score\n",
    "        overall_score = calculate_data_quality_score(metrics, df)\n",
    "        logger.info(f\"Overall Data Quality Score: {overall_score:.2f}\")\n",
    "\n",
    "        # 2. Integrate with Great Expectations:\n",
    "        # Define a threshold for the data quality score\n",
    "        quality_threshold = 0.8  # Example threshold: 0.8\n",
    "\n",
    "        if overall_score < quality_threshold:\n",
    "            logger.warning(f\"Data quality score ({overall_score:.2f}) is below the threshold ({quality_threshold}).  Triggering data cleaning.\")\n",
    "            df_cleaned = clean_data(df)  # Clean the data\n",
    "            df_cleaned.to_csv(file_path, index=False)  # Save the cleaned data back to the file\n",
    "            logger.info(\"Cleaned data saved to CSV file.\")\n",
    "\n",
    "            # Optionally, you could re-validate the cleaned data with Great Expectations\n",
    "            # to ensure the cleaning was effective.  This is good practice.\n",
    "            validation_status_after_cleaning = profile_data_with_great_expectations(file_path)\n",
    "            if validation_status_after_cleaning:\n",
    "                logger.info(\"Validation of cleaned data was successful.\")\n",
    "            else:\n",
    "                logger.error(\"Validation of cleaned data failed.\")\n",
    "\n",
    "            subject = \"Data Quality Alert and Automated Cleaning\"\n",
    "            body = (\n",
    "                f\"Data quality score ({overall_score:.2f}) fell below the threshold ({quality_threshold}).\\n\"\n",
    "                f\"Automated data cleaning was performed.  Please review the cleaned data in {file_path}.\"\n",
    "            )\n",
    "            send_email_alert(subject, body)\n",
    "        elif not validation_status or not anomaly_data.empty or not anomalous_age_data.empty: #send if GE validation fails or anomalies detected\n",
    "            subject = \"Data Quality and Anomaly Alert\"\n",
    "            body = f\"Data quality check failed at {datetime.datetime.now()}.  Please investigate the data in {file_path}.\"\n",
    "            if not validation_status:\n",
    "                body += \"\\n\\nGreat Expectations validation failed.\"\n",
    "            if not anomaly_data.empty:\n",
    "                body += \"\\n\\nAnomalies detected by Isolation Forest:\\n\"\n",
    "                body += anomaly_data.to_string()\n",
    "            if not anomalous_age_data.empty:\n",
    "                body += \"\\n\\nAnomalies detected in age column:\\n\"\n",
    "                body += anomalous_age_data.to_string()\n",
    "            body += f\"\\n\\nData Quality Metrics: {metrics}\" #append the metrics to email\n",
    "            body += f\"\\n\\nOverall Data Quality Score: {overall_score:.2f}\"\n",
    "            send_email_alert(subject, body)\n",
    "            logger.error(f\"Data quality check failed!\")\n",
    "        else:\n",
    "            logger.info(\"Data quality check successful.\")\n",
    "\n",
    "        time.sleep(60)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Get the file path from the user using st.text_input\n",
    "    default_file_path = \"data.csv\"  # Replace with your default CSV file name\n",
    "    file_path = st.text_input(\"Enter the path to your CSV file:\", default_file_path)\n",
    "\n",
    "    # Create a sample CSV file if it doesn't exist\n",
    "    if not pd.io.common.file_exists(file_path):\n",
    "        df = pd.DataFrame({\n",
    "            'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
    "            'Email': ['alice@example.com', 'bob@example.com', 'charlie@example.com', 'david.com', None],\n",
    "            'Age': [25, 30, 35, 40, 45]\n",
    "        })\n",
    "        df.to_csv(file_path, index=False)\n",
    "        st.info(f\"Created a sample CSV file at {file_path}.  You can replace this with your own data.\")\n",
    "\n",
    "    # Profile data with Pandas-Profiling\n",
    "    st.header(\"Data Profiling with Pandas-Profiling\")\n",
    "    profile_data_with_pandas_profiling(file_path)\n",
    "\n",
    "    # Profile data with Great Expectations\n",
    "    st.header(\"Data Profiling with Great Expectations\")\n",
    "    profile_data_with_great_expectations(file_path)\n",
    "\n",
    "    # Start real-time monitoring in a separate thread\n",
    "    monitoring_thread = threading.Thread(target=monitor_data_quality, args=(file_path,))\n",
    "    monitoring_thread.daemon = True  # Allow the main thread to exit\n",
    "    monitoring_thread.start()\n",
    "\n",
    "    st.subheader(\"Real-time Data Quality Monitoring\")\n",
    "    st.write(\"Data quality is being monitored in the background.  \"\n",
    "             \"Check the console for log messages and email alerts (if any issues are detected).\")\n",
    "\n",
    "    # Keep the main thread alive.\n",
    "    while True:\n",
    "        time.sleep(600)\n",
    "        st.info(\"The main thread is still alive. Monitoring is running in the background...\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
